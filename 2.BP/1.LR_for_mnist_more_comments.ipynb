{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 今日知识点预报\n",
    "- mnist\n",
    "- softmax\n",
    "- 逻辑回归是怎么到bp的\n",
    "- bp框架\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MNIST介绍\n",
    "ref: https://zhuanlan.zhihu.com/p/264960142 <br>\n",
    "首先下载mnist数据集<br>\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据加载和预处理"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    return ez / ez.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def load_labels(file):\n",
    "    '''\n",
    "    解码标签文件\n",
    "    '''\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()  # kp: 任务整理 readlines  readline  and read 的区别\n",
    "    \n",
    "    magic_number, num_samples = struct.unpack(\">ii\", data[:8])  # refer to magic_number.jpg  # struct.unpack refer to https://docs.python.org/3/library/struct.html\n",
    "                                                                # >ii refer to https://docs.python.org/3/library/struct.html\n",
    "    if magic_number != 2049:\n",
    "        print(f\"magic number mismatch {magic_number} != 2049\")\n",
    "        return None\n",
    "\n",
    "    labels = np.array(list(data[8:])) # np.asarray  \n",
    "    return labels\n",
    "\"\"\" \n",
    "稍稍了解一下\n",
    "大端字节序和小端字节序\n",
    "big-endian and little-endian\n",
    " \"\"\"\n",
    "\n",
    "def load_images(file):\n",
    "    with open(file, \"rb\") as f: # note rb or r\n",
    "        data = f.read()\n",
    "    \n",
    "    magic_number, num_samples, image_height, image_width = struct.unpack(\">iiii\", data[:16])\n",
    "\n",
    "    if magic_number != 2051:\n",
    "        print(f\"magic number mismatch {magic_number} != 2051\")\n",
    "        return None\n",
    "    \n",
    "    image_data = np.array(list(data[16:]), dtype=np.uint8).reshape(num_samples, -1) # dtype = \"uint8\"\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "\n",
    "train_labels = load_labels(\"dataset/train-labels-idx1-ubyte\")\n",
    "train_images = load_images(\"dataset/train-images-idx3-ubyte\")\n",
    "train_numdata = train_labels.shape[0] # 60000\n",
    "train_pd = pd.DataFrame(train_labels, columns = [\"label\"])\n",
    "\n",
    "val_labels = load_labels(\"dataset/t10k-labels-idx1-ubyte\") # 10000\n",
    "val_images = load_images(\"dataset/t10k-images-idx3-ubyte\") # 10000, 784\n",
    "val_numdata = val_labels.shape[0]    # 10000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 可视化数据 和 数据分析"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "# idx = 19\n",
    "# plt.imshow(train_images[idx][:-1].reshape(28,28)) # 可视化第五张图片来看看\n",
    "# _ = plt.title(f\"label = {train_labels[idx]}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "# np.ones((4,4), dtype = np.uint8)\n",
    "# np.ones((4,4), dtype = np.float32)\n",
    "# np.ones((4,4), dtype = np.float64) # 默认 64 \n",
    "# np.ones((4,4), dtype = \"float32\")\n",
    "# np.ones((4,4), dtype = \"float64\")\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    output = np.zeros((n, classes), dtype = np.int32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "    return output\n",
    "\n",
    "# one_hot(val_labels,10)\n",
    "\n",
    "def show_hist(labels, num_classes): # 常用的小工具函数的写法\n",
    "    label_map = {key: 0 for key in range(num_classes)} # 给每一个类都初始化： 数量为0\n",
    "    for label in labels:       # 循环labels，遇到label x  就去label x的keyvalue对里+1\n",
    "        label_map[label] += 1  # 这里相当于是一个一个label item去算\n",
    "    \n",
    "    # label_hist 是一个list, list 的值是 label_map key-value 对儿里的 value\n",
    "    labels_hist = [label_map[key] for key in range(num_classes)]  \n",
    "    pd.DataFrame(labels_hist, columns=[\"label\"]).plot(kind = \"bar\") # api 用法的形象记忆 refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "                                                                    # refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "show_hist(train_labels, 10)\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "train_pd.describe()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.453933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.889270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  60000.000000\n",
       "mean       4.453933\n",
       "std        2.889270\n",
       "min        0.000000\n",
       "25%        2.000000\n",
       "50%        4.000000\n",
       "75%        7.000000\n",
       "max        9.000000"
      ]
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "train_pd.value_counts()\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "label\n",
       "1        6742\n",
       "7        6265\n",
       "3        6131\n",
       "2        5958\n",
       "9        5949\n",
       "0        5923\n",
       "6        5918\n",
       "8        5851\n",
       "4        5842\n",
       "5        5421\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 100
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "train_labels"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "train_numdata, val_numdata"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "metadata": {},
     "execution_count": 101
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 创建管理数据和数据加载的类\n",
    "回顾一下我们线性回归和逻辑回归，我们是怎么做数据管理的\n",
    "我们其实并没有做, 为什么？\n",
    "<br>因为数据量少\n",
    "<br>现在我们跟原来相比，我们训练集有60000张图片，任何东西一多了，我们就要管理，所以我们要搞一些类对数据进行管理\n",
    "<br>我们提出了三个类，分别是\n",
    "<br>class Dataset &nbsp;&nbsp; class DataLoader  &nbsp;&nbsp;  class DataLoaderIterator\n",
    "<br>为什么呢？先形象理解一下 \n",
    "\n",
    "- 查看 manage_dataset.jpg\n",
    "- 涉及到的知识点\n",
    "\n",
    "    - 有__iter__和__next__  iterator   iterable\n",
    "    - Iterable : 只要对象实现了__iter__ 就是可迭代对象     但是有时候依然无法迭代，因为实际iterable 仅仅是提供了一种抽象规范的接口  （简化代码等作用）\n",
    "    - Iterator:    迭代器肯定是iterable 的     但是iterable 不一定是iterator。只有实现了__next__ 和__iterable__的才是迭代器。(不严谨地说，也就是可以被for循环了)。换句话说： 要想被for loop 必须实现__next__  和__iterable__\n",
    "\t\n",
    "    \n",
    "- 严谨地说法是：\n",
    "\t要想for .. in ..某个类实例\n",
    "\t- 1.要么直接在这个类下直接实现__iter__ 和__next__\n",
    "\t- 2.要么只实现__iter__ ，但是__iter__ 返回的的对象实现了__next__\n",
    "\n",
    "- 注意__getitem__ 属于__iter__ 和__next__的高级封装"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "class Dataset:\n",
    "    # 动态的，那么Dataset是个基类，所有动态的继承自Dataset\n",
    "    # 需要实现什么接口？\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "    # 针对mnist数据的解析、加载、预处理(e.g. /255 - 0.5), 加一个全是1的维度etc\n",
    "    def __init__(self, image_file, label_file):\n",
    "        self.num_classes = 10\n",
    "        self.images = load_images(image_file)\n",
    "        self.labels = load_labels(label_file)\n",
    "\n",
    "        # self.images = np.hstack((self.images / 255.0, np.ones((len(self.images), 1)))).astype(np.float32)\n",
    "        self.images = (self.images / 255.0).astype(np.float32)\n",
    "        self.labels_one_hot = one_hot(self.labels, self.num_classes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" \n",
    "        角色的职责\n",
    "        实现图像加载、归一化/标准化、onehot\n",
    "            为什么要返回one_hot，计算时，使用one_hot比较方便\n",
    "            为什么要返回label，因为做测试的时候，label比较方便\n",
    "            pytorch里面，CELoss使用的不是one_hot。所以以后不需要返回one_hot\n",
    "         \"\"\"\n",
    "        return self.images[index], self.labels[index], self.labels_one_hot[index]\n",
    "\n",
    "    # 获取数据集的长度，个数\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    职责\n",
    "    实例化的时候需要指定dataset，batch_size，shuffle\n",
    "    数据的封装，打包为一个batch\n",
    "    对数据进行打乱\n",
    "    可以通过迭代器来获取一批一批的数据\n",
    "     \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.count_data = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 实例化一个迭代器对象，将自身作为参数传入进去\n",
    "        return DataLoaderIterator(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" \n",
    "        用以告诉外界，多少次迭代，就算是完成一轮\n",
    "        这里有2种处理方法\n",
    "        1.向上取整\n",
    "        2.整除，向下取整，多余部分丢弃\n",
    "        这里考虑用策略2\n",
    "         \"\"\"\n",
    "        return len(self.dataset) // self.batch_size\n",
    "        \n",
    "\n",
    "class DataLoaderIterator:\n",
    "    \"\"\" \n",
    "    职责：\n",
    "        对打包好的batch一个一个的输出\n",
    "     \"\"\"\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        \n",
    "        # 这里有2中处理策略\n",
    "        # 1.向上取整\n",
    "        # 2.整除，向下取整，多余部分丢弃\n",
    "        # 这里考虑用方法2\n",
    "        self.num_batch_per_epoch = len(dataloader)\n",
    "        \n",
    "        # 定义指针记录当前batch的索引\n",
    "        self.batch_cursor = 0\n",
    "\n",
    "        # 实现一轮数据的打乱和封装获取\n",
    "        # 与其打乱数据，不如打乱索引\n",
    "        self.indexes = list(range(len(dataloader.dataset)))\n",
    "\n",
    "        # 如果需要随机打乱，条件控制由dataloader的shuffle决定\n",
    "        if dataloader.shuffle:\n",
    "            np.random.shuffle(self.indexes)  # inplace e.g. [0,1,2,3 ....59999] --> [2,1,48,23,...0]\n",
    "\n",
    "    \n",
    "    def __next__(self): # 指的是next batch\n",
    "        # 如果到了一轮的边界，即迭代结束，抛出异常 (一上来就做判断)\n",
    "        if self.batch_cursor >= self.num_batch_per_epoch:\n",
    "            # 如果到了边界，抛出StopIteration\n",
    "            raise StopIteration()\n",
    "        \"\"\" \n",
    "        职责：如何一个又一个的数据进行吐出, 每一行是一个数据\n",
    "            b1  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b2  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b3  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            ......\n",
    "            n 个 data\n",
    "        \n",
    "        images.shape = n x 784     labels.shape = n x 1        one_hot.shape = n x 10\n",
    "         \"\"\" \n",
    "\n",
    "        batch_data = []\n",
    "        for i in range(self.dataloader.batch_size): # 遍历一个batch里的图片\n",
    "            \"\"\" \n",
    "             拿到图像的索引，这个索引可能是打乱的\n",
    "              \"\"\"\n",
    "            index = self.indexes[self.batch_cursor * self.dataloader.batch_size + i] # 全局idx\n",
    "            \n",
    "            # 从dataset中拿到数据 e.g. 一个数据由图像和标签组成\n",
    "            data_item = self.dataloader.dataset[index]\n",
    "\n",
    "            if len(batch_data) == 0:\n",
    "                batch_data = [[] for _ in data_item] # 这里有3个\n",
    "            \n",
    "            # 把data_item中的每一项，分门别类的放到batch_data中\n",
    "            for index, item in enumerate(data_item):\n",
    "                batch_data[index].append(item)\n",
    "\n",
    "\n",
    "        # 遍历完了这个batch里的所有图片，要到下一个batch了\n",
    "        self.batch_cursor += 1\n",
    "\n",
    "        # 当整个batch的数据准备好过后，可以用np.vstack拼接在一起\n",
    "        for index in range(len(batch_data)):\n",
    "            batch_data[index] = np.vstack(batch_data[index])\n",
    "\n",
    "        return tuple(batch_data)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 各种init， 数据加载 和 数据预处理 权重初始化"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "source": [
    "# 初始化权重，和定义网络\n",
    "np.random.seed(3)\n",
    "num_train_images = train_images.shape[0]\n",
    "num_feature = train_images.shape[1]\n",
    "num_hidden = 256\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "lr = 0.1\n",
    "num_epochs = 30\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNIST_Dataset(\"dataset/train-images-idx3-ubyte\", \"dataset/train-labels-idx1-ubyte\")\n",
    "train_loader  = DataLoader(train_dataset, batch_size, True)\n",
    "test_dataset = MNIST_Dataset(\"dataset/t10k-images-idx3-ubyte\", \"dataset/t10k-labels-idx1-ubyte\")\n",
    "test_loader  = DataLoader(test_dataset, 512, True)\n",
    "\n",
    "\n",
    "# 初始化权重\n",
    "W = np.random.normal(0, 1, size = (num_feature, num_classes)) # (785, 10)\n",
    "W[:,-1] = 0.0\n",
    "b = -1\n",
    "# W\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for images, _, one_hot_labels in train_loader:\n",
    "        # print(images.shape, labels.shape, one_hots.shape)\n",
    "        # break\n",
    "        predict = images @ W + b\n",
    "        probability = softmax(predict)\n",
    "\n",
    "        # loss = -np.sum(one_hot_labels * np.log(probability) + (1 - one_hot_labels) * np.log(1 - probability)) / batch_size\n",
    "        loss = -np.sum(one_hot_labels * np.log(probability)) / batch_size\n",
    "\n",
    "        G = (probability - one_hot_labels) / batch_size\n",
    "\n",
    "        # matrix multiplication\n",
    "        del_W = images.T @ G\n",
    "        del_b = np.sum(G)\n",
    "        \n",
    "        W -= lr * del_W\n",
    "        b -= lr * del_b\n",
    "\n",
    "\n",
    "    # 每一个epoch 验证一次\n",
    "    correct = 0\n",
    "    for test_images, test_labels, test_one_hot_labels in test_loader:\n",
    "        predict = test_images @ W + b\n",
    "        predict_labels     = predict.argmax(axis=1).reshape(-1, 1)\n",
    "        \n",
    "        correct          += (predict_labels == test_labels).sum()\n",
    "    \n",
    "    acc = correct / len(test_dataset)\n",
    "    print(f\"{epoch}. train_Loss: {loss:.3f}, test_Accuracy: {acc:.5f}\")\n",
    "    \n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0. train_Loss: 0.847, test_Accuracy: 0.82370\n",
      "1. train_Loss: 0.750, test_Accuracy: 0.83960\n",
      "2. train_Loss: 0.722, test_Accuracy: 0.85580\n",
      "3. train_Loss: 0.085, test_Accuracy: 0.85730\n",
      "4. train_Loss: 0.603, test_Accuracy: 0.86430\n",
      "5. train_Loss: 0.405, test_Accuracy: 0.86700\n",
      "6. train_Loss: 0.179, test_Accuracy: 0.86920\n",
      "7. train_Loss: 0.576, test_Accuracy: 0.87400\n",
      "8. train_Loss: 0.642, test_Accuracy: 0.87370\n",
      "9. train_Loss: 0.205, test_Accuracy: 0.87270\n",
      "10. train_Loss: 0.995, test_Accuracy: 0.87590\n",
      "11. train_Loss: 0.323, test_Accuracy: 0.87590\n",
      "12. train_Loss: 0.084, test_Accuracy: 0.87970\n",
      "13. train_Loss: 0.718, test_Accuracy: 0.87920\n",
      "14. train_Loss: 0.060, test_Accuracy: 0.88290\n",
      "15. train_Loss: 0.564, test_Accuracy: 0.88210\n",
      "16. train_Loss: 0.158, test_Accuracy: 0.88080\n",
      "17. train_Loss: 0.123, test_Accuracy: 0.88260\n",
      "18. train_Loss: 0.090, test_Accuracy: 0.88140\n",
      "19. train_Loss: 0.351, test_Accuracy: 0.88370\n",
      "20. train_Loss: 0.478, test_Accuracy: 0.88500\n",
      "21. train_Loss: 0.209, test_Accuracy: 0.88650\n",
      "22. train_Loss: 0.325, test_Accuracy: 0.88680\n",
      "23. train_Loss: 0.809, test_Accuracy: 0.88790\n",
      "24. train_Loss: 0.311, test_Accuracy: 0.88640\n",
      "25. train_Loss: 0.348, test_Accuracy: 0.88870\n",
      "26. train_Loss: 0.254, test_Accuracy: 0.88650\n",
      "27. train_Loss: 0.058, test_Accuracy: 0.89020\n",
      "28. train_Loss: 0.194, test_Accuracy: 0.88790\n",
      "29. train_Loss: 0.245, test_Accuracy: 0.88860\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7383003b210fdacca9bf7683d9d1d561f4a72c77adad40daede406a89507eb7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}