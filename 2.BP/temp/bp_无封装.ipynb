{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# 解析数据集中的二进制用的\n",
    "import struct\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def decode_labels(file):\n",
    "    '''\n",
    "    解码标签文件\n",
    "    '''\n",
    "    \n",
    "    # rb  ->  read binary\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "        \n",
    "    # 大端方式解析出2个int32，返回的是tuple(int1, int2)\n",
    "    # int1 -> magic number，用来验证数据是否是目标数据\n",
    "    _, num_items = struct.unpack_from(\">II\", binary_data, 0)\n",
    "    labels = struct.unpack_from(\"B\" * num_items, binary_data, 8)\n",
    "    return np.array(labels).reshape(-1, 1).astype(np.int32)\n",
    "\n",
    "def decode_images(file):\n",
    "    '''\n",
    "    解码图像数据\n",
    "    '''\n",
    "    \n",
    "    # rb  ->  read binary\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "        \n",
    "    # 大端方式解析出4个int32，返回的是tuple(magic number, num images, rows, cols)\n",
    "    _, num_images, rows, cols = struct.unpack_from(\">IIII\", binary_data, 0)\n",
    "    images = struct.unpack_from(\"B\" * num_images * rows * cols, binary_data, 16)\n",
    "    return np.array(images).reshape(-1, rows * cols)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "test_labels = decode_labels(\"dataset/t10k-labels-idx1-ubyte\")\n",
    "test_images = decode_images(\"dataset/t10k-images-idx3-ubyte\")\n",
    "train_labels = decode_labels(\"dataset/train-labels-idx1-ubyte\")\n",
    "train_images = decode_images(\"dataset/train-images-idx3-ubyte\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "plt.imshow(train_images[5].reshape(28, 28))\n",
    "_ = plt.title(f\"label = {train_labels[5][0]}\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BP的实现1，直接实现，不做任何封装\n",
    "1. 网络有2个Linear层\n",
    "2. 隐层节点数256\n",
    "3. 使用Softmax Cross Entropy Loss\n",
    "4. minbatch的大小设置为100\n",
    "5. 学习率给0.1\n",
    "6. 迭代轮数给10轮\n",
    "7. 优化器，用SGD"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# 初始化，超参数\n",
    "np.random.seed(3)\n",
    "num_train_images = train_images.shape[0]\n",
    "num_feature   = train_images.shape[1]\n",
    "num_hidden    = 256\n",
    "num_classes   = 10\n",
    "batch_size    = 100\n",
    "learning_rate = 0.1\n",
    "epochs        = 10\n",
    "\n",
    "# 策略1，丢掉不足一个batch的数据，反正下次还可以看到它\n",
    "# 策略2，不足一个batch的数据，依旧训练\n",
    "num_batch_per_epoch = num_train_images // batch_size\n",
    "\n",
    "# 初始化参数\n",
    "# 行是输入维度，列是输出维度，对于bias来讲，输入恒等于1，所以维度是1x输出\n",
    "layer1_weight = np.random.normal(0, 1 / np.sqrt(num_feature), size=(num_feature, num_hidden))\n",
    "layer1_bias   = np.zeros((1, num_hidden))\n",
    "\n",
    "layer2_weight = np.random.normal(0, 1 / np.sqrt(num_hidden), size=(num_hidden, num_classes))\n",
    "layer2_bias   = np.zeros((1, num_classes))\n",
    "\n",
    "\n",
    "# 定义数据相关的操作，以及索引\n",
    "train_images_index = list(range(num_train_images))\n",
    "\n",
    "\n",
    "# 定义sigmoid函数实现\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    ex = np.exp(x)\n",
    "    return ex / ex.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    \n",
    "    # 每个epoch打乱索引\n",
    "    np.random.shuffle(train_images_index)\n",
    "\n",
    "    for batch_index in range(num_batch_per_epoch):\n",
    "        \n",
    "        # 取一个批次的索引\n",
    "        batch_begin = batch_index * batch_size\n",
    "        batch_end = min(batch_begin + batch_size, num_train_images)\n",
    "        batch_images_index = train_images_index[batch_begin:batch_end]\n",
    "        \n",
    "        # 按照索引batch_images_index，取对应的一个批次的图像\n",
    "        batch_images = train_images[batch_images_index]\n",
    "        batch_labels = train_labels[batch_images_index]\n",
    "        \n",
    "        # 数据预处理\n",
    "        batch_images = (batch_images / 255 - 0.5).astype(np.float32)\n",
    "        \n",
    "        # label变换为onehot\n",
    "        batch_onehot_labels = np.zeros((batch_size, num_classes))\n",
    "        for row, col in enumerate(batch_labels):\n",
    "            batch_onehot_labels[row, col] = 1\n",
    "        \n",
    "        # 推理呀\n",
    "        hidden = batch_images @ layer1_weight + layer1_bias\n",
    "        hidden_activation = sigmoid(hidden)\n",
    "        output = hidden_activation @ layer2_weight + layer2_bias\n",
    "        \n",
    "        # Softmax Cross Entropy Loss计算\n",
    "        probability = softmax(output)\n",
    "        loss = -np.sum(batch_onehot_labels * np.log(probability)) / batch_size\n",
    "        \n",
    "        # 反向求导\n",
    "        # L对output求导\n",
    "        # deltaB = A.T @ G\n",
    "        # deltaA = G @ B.T\n",
    "        delta_output            = (probability - batch_onehot_labels) / batch_size\n",
    "        delta_layer2_bias       = np.sum(delta_output, axis=0)\n",
    "        delta_layer2_weight     = hidden_activation.T @ delta_output\n",
    "        delta_hidden_activation = delta_output @ layer2_weight.T\n",
    "        delta_hidden            = delta_hidden_activation * sigmoid(hidden) * (1 - sigmoid(hidden))\n",
    "        delta_layer1_bias       = np.sum(delta_hidden, axis=0)\n",
    "        delta_layer1_weight     = batch_images.T @ delta_hidden\n",
    "        \n",
    "        # SGD优化器，更新参数\n",
    "        layer2_bias             -= learning_rate * delta_layer2_bias\n",
    "        layer2_weight           -= learning_rate * delta_layer2_weight\n",
    "        layer1_bias             -= learning_rate * delta_layer1_bias\n",
    "        layer1_weight           -= learning_rate * delta_layer1_weight\n",
    "        \n",
    "    norm_test_images  = (test_images / 255 - 0.5).astype(np.float32)\n",
    "    hidden            = norm_test_images @ layer1_weight + layer1_bias\n",
    "    hidden_activation = sigmoid(hidden)\n",
    "    output            = hidden_activation @ layer2_weight + layer2_bias\n",
    "    probability       = softmax(output)\n",
    "    predict_label     = probability.argmax(axis=1).reshape(-1, 1)\n",
    "    accuracy          = (predict_label == test_labels).sum() / test_labels.shape[0]\n",
    "    print(f\"{epoch_index}. Loss: {loss:.3f}, Accuracy: {accuracy:.5f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0. Loss: 0.472, Accuracy: 0.87380\n",
      "1. Loss: 0.363, Accuracy: 0.90050\n",
      "2. Loss: 0.331, Accuracy: 0.90650\n",
      "3. Loss: 0.330, Accuracy: 0.91230\n",
      "4. Loss: 0.244, Accuracy: 0.91210\n",
      "5. Loss: 0.270, Accuracy: 0.91910\n",
      "6. Loss: 0.319, Accuracy: 0.91980\n",
      "7. Loss: 0.183, Accuracy: 0.92110\n",
      "8. Loss: 0.249, Accuracy: 0.92500\n",
      "9. Loss: 0.174, Accuracy: 0.92720\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "norm_test_images  = (test_images / 255 - 0.5).astype(np.float32)\n",
    "hidden            = norm_test_images @ layer1_weight + layer1_bias\n",
    "hidden_activation = sigmoid(hidden)\n",
    "output            = hidden_activation @ layer2_weight + layer2_bias\n",
    "probability       = softmax(output)\n",
    "predict_label     = probability.argmax(axis=1).reshape(-1, 1)\n",
    "accuracy          = (predict_label == test_labels).sum() / test_labels.shape[0]\n",
    "accuracy"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9272"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 考虑\n",
    "1. 数据模块的封装，更加通用化\n",
    "    - 目前有这么个任务，如何划分为不同人负责不同事。有几个角色？每角色的工作边界是怎样？相互之间如何协作？划分粒度如何考虑？如果规定工作流程，使得该流程能够在任意复杂的数据集上稳定工作而不用变动？\n",
    "        - 任务：\n",
    "            - 给定数据集，将数据集进行解析、加载。在需要的时候，对数据进行封装，每次随机加载一个批次的数据和标签。对于数据进行标准化/归一化，对标签进行onehot编码\n",
    "        - 角色：\n",
    "            - 数据集：负责数据的解析、加载、标准化/归一化，onehot\n",
    "            - 加载器：负责在需要的时候对数据封装，每次随机加载一个批次数据\n",
    "    - 实现：\n",
    "        - 数据集[动态]：负责数据的解析、加载、标准化/归一化，onehot\n",
    "            - 每次有新的任务，就开发一个新的数据集角色\n",
    "                - 因为每个新的任务通常数据集的解析方式、加载方式，标准化方式等都不太一样。因此针对不同任务动态开发即可\n",
    "            - 提供数据集的获取接口，使用\\_\\_getitem\\_\\_\n",
    "                - 通过该接口，根据索引获取一个数据。返回的数据中，包含了图像、标签等不限定个数\n",
    "                - 同时商定好数据集提供的数据的0维度是batch维度，加载器根据0维度进行拼接\n",
    "            - 提供数据集规模的接口，使用\\_\\_len\\_\\_\n",
    "        - 加载器[静态]：负责在需要的时候对数据封装，每次随机加载一个批次数据\n",
    "            - 数据的封装（打包为一个矩阵），随机处理方式（shuffle）可以固定下来，绝大部分任务的需求都能够满足\n",
    "            - 重点，所有的数据均来自数据集角色传递过来。因此加载器不区分数据是什么，仅仅是对数据进行封装拼接\n",
    "            - 对于任何新任务的处理，只需要实现特定数据集相关的解析、加载、标准化等操作。加载器不用改变\n",
    "            - 通过 for images, labels in loader的方式，即可拿到每一个批次数据，并且是打乱的。使用者只需要考虑指定批次大小即可控制批次的数量\n",
    "2. 关于计算的封装\n",
    "    - 如何封装细节，使得计算得以模块化，如何划分角色？角色如何分工？，相互如何协作？每层的计算是多种可能，优化的方式也是大有不同，模型的结构需要具有足够的灵活度，由开发者控制结构\n",
    "    - 任务：\n",
    "        - 给定输入数据和标签，定义参数和模型结构（function set，或者说是计算图），将数据按照function set/计算图执行运算得到预测结果，并计算loss，然后反向计算偏导数，链式法则求参数的梯度。得到梯度后，根据优化策略或方法应用梯度到参数中实现更新。循环这个过程\n",
    "            - 计算图的每个算子可以作为一个单位抽象\n",
    "            - 计算图中的计算，可以看做是数据的流动。而数据又分为“数据”和“参数”两个部分。tensorflow就是tensor在计算图中流动\n",
    "    - 图表示：\n",
    "        - <img src=\"关于抽象.png\" />\n",
    "        - 对计算人物分派个“层”角色做，参数与计算合为一体\n",
    "        - 整个模型，则可以表示为多个层以图的形式构建的结果。数据则根据图结构在中间进行扭转实现前向、反过来根据图结构链式求导得到参数导数\n",
    "    - 角色：\n",
    "        - 数据：一部分由加载器产生的一个批次数据，另一部分由计算图的算子产生的中间数据\n",
    "        - 层：对于每个算子（计算为主）抽象为具有“输入”数据，具有“输出”数据，和具有“参数”的一个整体。负责完成计算工作\n",
    "            - 计算包括了forward前向推理，和backward反向求导\n",
    "        - 参数：负责计算图中需要使用的参数，以及每个参数都需要对应的梯度。参数与算子封装成一个整体，作为算子的属性存在\n",
    "            - data储存参数，grad储存梯度\n",
    "        - 模型：作为一个整体算子，负责完成整个数据从输入到输出的过程。模型可以定义内部的计算图结构，该结构由多个算子（层）组成。模型描述了不同算子之间的数据扭转\n",
    "        - 优化器：对给定图结构（模型）中所有的参数，使用参数对应的梯度进行特定方式的更新。被称为优化方法\n",
    "            - 我们其实知道，有了梯度，优化的方法有多种。不同方法具有不同效果\n",
    "- 角色之间的互相关系\n",
    "    - <img src=\"关于抽象后的相互关系.png\" />"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "7383003b210fdacca9bf7683d9d1d561f4a72c77adad40daede406a89507eb7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}