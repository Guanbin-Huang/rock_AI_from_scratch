{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/gdrive')"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JER9O6Ryl2Kp",
    "outputId": "a6dadfb0-19af-481e-dbe3-93e51dc8b0cd"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# %cd /gdrive/My Drive/\n",
    "# %cp -av mnist.zip /content/\n",
    "# %cd /content/\n",
    "\n",
    "# !unzip mnist.zip"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k6avFTz5p_tu",
    "outputId": "ab5972ac-d621-4ad1-d97b-fa0cff4cbfae"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "CBbOQboJjFFN"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\n",
    "def load_labels(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    magic_number, num_samples = struct.unpack(\">ii\", data[:8])\n",
    "    if magic_number != 2049:  # 0x00000801\n",
    "        print(f\"magic number mismatch {magic_number} != 2049\")\n",
    "        return None\n",
    "\n",
    "    labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "def load_images(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()\n",
    "\n",
    "    magic_number, num_samples, image_width, image_height = struct.unpack(\">iiii\", data[:16])\n",
    "    if magic_number != 2051:  # 0x00000803\n",
    "        print(f\"magic number mismatch {magic_number} != 2051\")\n",
    "        return None\n",
    "\n",
    "    image_data = np.frombuffer(data[16:], dtype=np.uint8).reshape(num_samples, -1)\n",
    "    return image_data\n",
    "\n",
    "def one_hot(labels, classes, label_smoothing=0):\n",
    "    n = len(labels)\n",
    "    eoff = label_smoothing / classes\n",
    "    output = np.ones((n, classes), dtype=np.float32) * eoff\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1 - label_smoothing + eoff\n",
    "    return output\n",
    "\n",
    "class Dataset:\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    # 获取他的一个item，  dataset = Dataset(),   dataset[index]\n",
    "    def __getitem__(self, index):\n",
    "        return self.images[index], self.labels[index]\n",
    "\n",
    "    # 获取数据集的长度，个数\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "class DataLoaderIterator:\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        self.cursor = 0\n",
    "        self.indexs = list(range(self.dataloader.count_data))  # 0, ... 60000\n",
    "        if self.dataloader.shuffle:\n",
    "            # 打乱一下\n",
    "            random.shuffle(self.indexs)\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.cursor >= self.dataloader.count_data:\n",
    "            raise StopIteration()\n",
    "\n",
    "        batch_data = []\n",
    "        remain = min(self.dataloader.batch_size, self.dataloader.count_data - self.cursor)  # 256, 128\n",
    "        for n in range(remain):\n",
    "            index = self.indexs[self.cursor]\n",
    "            data = self.dataloader.dataset[index]\n",
    "\n",
    "            # 如果batch没有初始化，则初始化n个list成员\n",
    "            if len(batch_data) == 0:\n",
    "                batch_data = [[] for i in range(len(data))]\n",
    "\n",
    "            # 直接append进去\n",
    "            for index, item in enumerate(data):\n",
    "                batch_data[index].append(item)\n",
    "            self.cursor += 1\n",
    "\n",
    "        # 通过np.vstack一次性实现合并，而非每次一直在合并\n",
    "        for index in range(len(batch_data)):\n",
    "            batch_data[index] = np.vstack(batch_data[index])\n",
    "        return batch_data\n",
    "\n",
    "class DataLoader:\n",
    "\n",
    "    # shuffle 打乱\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.count_data = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return DataLoaderIterator(self)\n",
    "\n",
    "\n",
    "def estimate(plabel, gt_labels, classes):\n",
    "    plabel = plabel.copy()\n",
    "    gt_labels = gt_labels.copy()\n",
    "    match_mask = plabel == classes\n",
    "    mismatch_mask = plabel != classes\n",
    "    plabel[match_mask] = 1\n",
    "    plabel[mismatch_mask] = 0\n",
    "    \n",
    "    gt_mask = gt_labels == classes\n",
    "    gt_mismatch_mask = gt_labels != classes\n",
    "    gt_labels[gt_mask] = 1\n",
    "    gt_labels[gt_mismatch_mask] = 0\n",
    "    \n",
    "    TP = sum(plabel & gt_labels)\n",
    "    FP = sum(plabel & (1 - gt_labels))\n",
    "    FN = sum((1 - plabel) & gt_labels)\n",
    "    TN = sum((1 - plabel) & (1 - gt_labels))\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    F1 = 2 * (precision * recall) / (precision + recall)\n",
    "    return precision, recall, accuracy, F1\n",
    "\n",
    "def estimate_val(predict, gt_labels, classes, loss_func):\n",
    "    plabel = predict.argmax(1)\n",
    "    positive = plabel == val_labels\n",
    "    total_images = predict.shape[0]\n",
    "    accuracy = sum(positive) / total_images\n",
    "    return accuracy, loss_func(predict, one_hot(gt_labels, classes))\n",
    "\n",
    "\n",
    "def lr_cosine_schedule(lr_min, lr_max, Ti):\n",
    "    '''\n",
    "    :param Ti: Ti epochs are performed before a new restart.\n",
    "    :param Tcur: How many epochs have been performed since the last restart.\n",
    "    :return: a function to compute a value within a period.\n",
    "    '''\n",
    "    def compute(Tcur):\n",
    "        return lr_min + 0.5 * (lr_max - lr_min) * (1 + np.cos(Tcur / Ti * np.pi))\n",
    "    return compute\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    p0= x<0 \n",
    "    p1 = ~p0 # 补集\n",
    "    x = x.copy()\n",
    "    x[p0] = np.exp(x[p0])/(np.exp(x[p0])+1)\n",
    "    x[p1] = 1/(1+np.exp(-x[p1]))\n",
    "    return x\n",
    "\n",
    "def softmax(x):\n",
    "    x = x.copy()\n",
    "    x_max = np.max(x,axis = 1)\n",
    "    exp_x = np.exp(x-x_max)\n",
    "    return exp_x /np.sum(exp_x,axis = 1,keepdims = True)\n",
    "\n",
    "\n",
    "def cross_entropy(predict, gt):\n",
    "    eps = 1e-4\n",
    "    predict = np.clip(predict, a_max=1-eps, a_min=eps)  # 裁切\n",
    "    batch_size = predict.shape[0]\n",
    "    return -np.sum(gt * np.log(predict) + (1 - gt) * np.log(1 - predict)) / batch_size # loss for one batch\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     25,
     33,
     46,
     79,
     92,
     116,
     124,
     136,
     144,
     151
    ],
    "id": "Svf0XcbXk5w3"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Module:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.train_mode = False\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def train(self):\n",
    "        self.train_mode = True\n",
    "        for m in self.modules():\n",
    "            m.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.train_mode = False\n",
    "        for m in self.modules():\n",
    "            m.eval()\n",
    "\n",
    "    def modules(self):\n",
    "        ms = []\n",
    "        for attr in self.__dict__:\n",
    "            m = self.__dict__[attr]\n",
    "            if isinstance(m, Module):\n",
    "                ms.append(m)\n",
    "        return ms\n",
    "\n",
    "    def params(self):\n",
    "        ps = []\n",
    "        for attr in self.__dict__:\n",
    "            p = self.__dict__[attr]\n",
    "            if isinstance(p, Parameter):\n",
    "                ps.append(p)\n",
    "\n",
    "        ms = self.modules()\n",
    "        for m in ms:\n",
    "            ps.extend(m.params())\n",
    "        return ps\n",
    "\n",
    "    def info(self, n):\n",
    "        ms = self.modules()\n",
    "        output = f\"{self.name}\\n\"\n",
    "        for m in ms:\n",
    "            output += (' ' * (n + 1)) + f\"{m.info(n + 1)}\\n\"\n",
    "        return output[:-1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.info(0)\n",
    "\n",
    "class ModuleList(Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__(\"ModuleList\")\n",
    "        self.ms = list(args)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'self.ms'\n",
    "    \n",
    "    def modules(self):\n",
    "        return self.ms\n",
    "\n",
    "    def forward(self, x):\n",
    "        for m in self.ms:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, G):\n",
    "        for i in range(len(self.ms) - 1, -1, -1):\n",
    "            G = self.ms[i].backward(G)\n",
    "        return G\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, num_feature, num_hidden, num_classes):\n",
    "        super().__init__(\"Model\")\n",
    "        self.backbone = ModuleList(\n",
    "            Linear(num_feature, num_hidden),\n",
    "            ReLU(),\n",
    "            # Dropout(),\n",
    "            Linear(num_hidden, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "    def backward(self, G):\n",
    "        return self.backbone.backward(G)\n",
    "\n",
    "class Initializer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def __call__(self, *args):\n",
    "        return self.apply(*args)\n",
    "\n",
    "class GaussInitializer(Initializer):\n",
    "    # where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
    "    # deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
    "    # is called the variance.\n",
    "    def __init__(self, mu, sigma):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def apply(self, value):\n",
    "        value[...] = np.random.normal(self.mu, self.sigma, value.shape)\n",
    "\n",
    "class Parameter:\n",
    "    def __init__(self, value):\n",
    "        self.value = value\n",
    "        self.delta = np.zeros(value.shape)\n",
    "\n",
    "    def zero_grad(self):\n",
    "        self.delta[...] = 0\n",
    "\n",
    "class Linear(Module):\n",
    "    def __init__(self, input_feature, output_feature):\n",
    "        super().__init__(\"Linear\")\n",
    "        self.input_feature = input_feature\n",
    "        self.output_feature = output_feature\n",
    "        self.weights = Parameter(np.zeros((input_feature, output_feature)))\n",
    "        self.bias = Parameter(np.zeros((1, output_feature)))\n",
    "\n",
    "        # 权重初始化\n",
    "        initer = GaussInitializer(0, np.sqrt(2 / input_feature))# kaiming初始化\n",
    "        initer.apply(self.weights.value)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_save = x.copy()\n",
    "        return x @ self.weights.value + self.bias.value\n",
    "\n",
    "    # AB = C  G\n",
    "    # dB = A.T @ G\n",
    "    # dA = G @ B.T\n",
    "    def backward(self, G):\n",
    "        self.weights.delta += self.x_save.T @ G \n",
    "        # +=是因为考虑了多个batch后再更新；这里不用/batch_size 是因为回传的第一个G\n",
    "        # 也就是loss 的G 已经除以了batchsize 了。\n",
    "        self.bias.delta += np.sum(G, 0)  # 值复制\n",
    "        return G @ self.weights.value.T\n",
    "\n",
    "class ReLU(Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super().__init__(\"ReLU\")\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x_negative = x < 0\n",
    "        if not self.inplace:\n",
    "            x = x.copy()\n",
    "\n",
    "        x[self.x_negative] = 0\n",
    "        return x\n",
    "\n",
    "    def backward(self, G):\n",
    "        if not self.inplace:\n",
    "            G = G.copy()\n",
    "\n",
    "        G[self.x_negative] = 0\n",
    "        return G\n",
    "\n",
    "class Dropout(Module):\n",
    "    def __init__(self,pro_keep = 0.5, inplace = True):\n",
    "        super().__init__(\"Dropout\")\n",
    "        self.pro_keep = pro_keep\n",
    "        self.inplace = inplace\n",
    "    \n",
    "    def forward(self,x):\n",
    "        if not self.train_mode:\n",
    "            return x\n",
    "        \n",
    "        self.mask = np.random.binomial(size = x.shape, p = 1-self.pro_keep, n =1)\n",
    "        if not inplace:\n",
    "            x = x.copy()\n",
    "        x[self.mask] = 0# 压制住每层false的输入神经元\n",
    "        x *= 1/self.pro_keep # 需要rescale\n",
    "        return x\n",
    "    \n",
    "    def backward(self,G):\n",
    "        if not self.train_mode:\n",
    "            return G\n",
    "        \n",
    "        if not inplace:\n",
    "            G = G.copy()\n",
    "        \n",
    "        G[self.mask] = 0\n",
    "        G *= 1/self.pro_keep\n",
    "        return G\n",
    "        \n",
    "        \n",
    "\n",
    "class SigmoidCrossEntropy(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"CrossEntropyLoss\")\n",
    "\n",
    "    def forward(self,x,one_hot_labels):\n",
    "        self.labels = one_hot_labels\n",
    "        self.predict = sigmoid(x)\n",
    "        self.batch_size = self.predict.shape[0]\n",
    "        loss = cross_entropy(self.predict,self.labels)/self.batch_size # loss for one batch\n",
    "        return loss\n",
    "\n",
    "    def backward(self):\n",
    "        return (self.predict - self.labels)/self.batch_size\n",
    "\n",
    "class SoftmaxCrossEntropy(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"SoftmaxCrossEntropy\")\n",
    "  \n",
    "    def forward(self,x,one_hot_labels):\n",
    "        self.predict = softmax(x)\n",
    "        self.labels = one_hot_labels\n",
    "        self.batch_size = self.predict.shape[0]\n",
    "        loss = cross_entropy(self.predict,self.labels)/self.batch_size # loss for one batch\n",
    "        return loss\n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self, name, model, lr):\n",
    "        self.name = name\n",
    "        self.model = model\n",
    "        self.lr = lr\n",
    "        self.params = model.params()\n",
    "\n",
    "    def zero_grad(self):\n",
    "        for param in self.params:\n",
    "            param.zero_grad()\n",
    "\n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, model, lr=1e-3):\n",
    "        super().__init__(\"SGD\", model, lr)\n",
    "\n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.value -= self.lr * param.delta\n",
    "\n",
    "class Adam(Optimizer):# l2 和adam不要一起用 https://zhuanlan.zhihu.com/p/63982470\n",
    "    def __init__(self, model, lr=1e-3, beta1=0.9, beta2=0.999):\n",
    "        super().__init__(\"Adam\", model, lr)\n",
    "        self.beta1 = beta1\n",
    "        self.beta2 = beta2\n",
    "        self.t = 0\n",
    "\n",
    "        for param in self.params:\n",
    "            param.m = 0 # w和b参数多了m v两个属性\n",
    "            param.v = 0\n",
    "  \n",
    "    def step(self):\n",
    "        eps = 1e-8\n",
    "        self.t += 1\n",
    "        for param in self.params:\n",
    "            g = param.delta\n",
    "            param.m = self.beta1 * param.m +(1-self.beta1)*g\n",
    "            param.v = self.beta2* param.v  + (1-self.beta2)*g**2\n",
    "\n",
    "            param.m_ = param.m/(1-self.beta1**self.t)\n",
    "            param.v_ = param.v/(1-self.beta2**self.t)\n",
    "\n",
    "            param.value -= self.lr*param.m_/(np.sqrt(param.v_)+ eps) \n",
    "\n",
    "\n",
    "\n",
    "def estimate_val(predict, gt_labels, classes, loss_func):\n",
    "    plabel = predict.argmax(1)\n",
    "    positive = plabel == gt_labels\n",
    "    total_images = predict.shape[0]\n",
    "    accuracy = sum(positive) / total_images\n",
    "    return accuracy, loss_func(predict, one_hot(gt_labels, classes))\n",
    "\n",
    "def lr_schedule_cosine(lr_min, lr_max, per_epochs):\n",
    "    def compute(epoch):\n",
    "        return lr_min + 0.5 * (lr_max - lr_min) * (1 + np.cos(epoch / per_epochs * np.pi))\n",
    "\n",
    "    return compute\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": [
     48,
     69,
     85,
     92,
     103,
     111,
     137,
     157,
     187,
     201,
     213,
     235,
     261,
     268
    ],
    "id": "Ml-utJ8KjGNg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "val_labels = load_labels('./mnist/t10k-labels.idx1-ubyte')  # 10000,\n",
    "val_images = load_images('./mnist/t10k-images.idx3-ubyte')  # 10000, 784\n",
    "val_images = (val_images - np.mean(val_images)) / np.var(val_images) # 除以方差还是标准差实验一下\n",
    "# val_images = val_images / 255 - 0.5\n",
    "\n",
    "train_labels = load_labels('./mnist/train-labels.idx1-ubyte')  # 60000,\n",
    "train_images = load_images('./mnist/train-images.idx3-ubyte')  # 60000, 784\n",
    "# train_images = train_images / 255 - 0.5\n",
    "train_images = (train_images - np.mean(train_images)) / np.var(train_images)\n"
   ],
   "outputs": [],
   "metadata": {
    "id": "wMsLS90rt1lw"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "np.random.seed(3)\n",
    "classes = 10  # 定义10个类别\n",
    "batch_size = 64  # 定义每个批次的大小\n",
    "epochs = 20  # 退出策略，也就是最大把所有数据看10次\n",
    "lr = 1e-2\n",
    "numdata, data_dims = train_images.shape  # 60000, 784\n",
    "\n",
    "# 定义dataloader和dataset，用于数据抓取\n",
    "train_data = DataLoader(Dataset(train_images, one_hot(train_labels, classes)), batch_size, shuffle=True)\n",
    "model = Model(data_dims, 1024, classes)\n",
    "\n",
    "loss_func = SigmoidCrossEntropy()\n",
    "\n",
    "optim = SGD(model, lr)\n",
    "iters = 0  # 定义迭代次数，因为我们需要展示loss曲线，那么x将会是iters\n",
    "\n",
    "lr_schedule = {\n",
    "    5: 1e-3,\n",
    "    15: 1e-4,\n",
    "    18: 1e-5\n",
    "}\n",
    "\n",
    "# 开始进行epoch循环，总数是epochs次\n",
    "for epoch in range(epochs):\n",
    "    if epoch in lr_schedule:\n",
    "#         lr = lr_schedule[epoch]\n",
    "        optim.set_lr(lr)\n",
    "\n",
    "    model.train()\n",
    "    # 对一个批次内的数据进行迭代，每一次迭代都是一个batch（即256）\n",
    "    for index, (images, labels) in enumerate(train_data):\n",
    "        x = model(images)\n",
    "\n",
    "        # 计算loss值\n",
    "        loss = loss_func(x, labels)\n",
    "        optim.zero_grad()\n",
    "        G = loss_func.backward()\n",
    "        model.backward(G)\n",
    "        optim.step()   # 应用梯度，更新参数\n",
    "        iters += 1\n",
    "\n",
    "    print(f\"Iter {iters}, {epoch} / {epochs}, Loss {loss:.3f}, LR {lr:g}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_accuracy, val_loss = estimate_val(model(val_images), val_labels, classes, loss_func)\n",
    "    print(f\"Val set, Accuracy: {val_accuracy:.6f}, Loss: {val_loss:.3f}\")\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Iter 938, 0 / 20, Loss 0.100, LR 0.01\n",
      "Val set, Accuracy: 0.228500, Loss: 0.000\n",
      "Iter 1876, 1 / 20, Loss 0.098, LR 0.01\n",
      "Val set, Accuracy: 0.514300, Loss: 0.000\n",
      "Iter 2814, 2 / 20, Loss 0.095, LR 0.01\n",
      "Val set, Accuracy: 0.580500, Loss: 0.000\n",
      "Iter 3752, 3 / 20, Loss 0.095, LR 0.01\n",
      "Val set, Accuracy: 0.635500, Loss: 0.000\n",
      "Iter 4690, 4 / 20, Loss 0.091, LR 0.01\n",
      "Val set, Accuracy: 0.674700, Loss: 0.000\n",
      "Iter 5628, 5 / 20, Loss 0.085, LR 0.01\n",
      "Val set, Accuracy: 0.684700, Loss: 0.000\n",
      "Iter 6566, 6 / 20, Loss 0.081, LR 0.01\n",
      "Val set, Accuracy: 0.687000, Loss: 0.000\n",
      "Iter 7504, 7 / 20, Loss 0.083, LR 0.01\n",
      "Val set, Accuracy: 0.719200, Loss: 0.000\n",
      "Iter 8442, 8 / 20, Loss 0.069, LR 0.01\n",
      "Val set, Accuracy: 0.730900, Loss: 0.000\n",
      "Iter 9380, 9 / 20, Loss 0.068, LR 0.01\n",
      "Val set, Accuracy: 0.756100, Loss: 0.000\n",
      "Iter 10318, 10 / 20, Loss 0.067, LR 0.01\n",
      "Val set, Accuracy: 0.764500, Loss: 0.000\n",
      "Iter 11256, 11 / 20, Loss 0.063, LR 0.01\n",
      "Val set, Accuracy: 0.774500, Loss: 0.000\n",
      "Iter 12194, 12 / 20, Loss 0.059, LR 0.01\n",
      "Val set, Accuracy: 0.782600, Loss: 0.000\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-58c05ca2e6c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mG\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 应用梯度，更新参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0miters\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-dad70d8dc855>\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m# l2 和adam不要一起用 https://zhuanlan.zhihu.com/p/63982470\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "usVOVRE6t7Ee",
    "outputId": "b16ac850-ea1c-4942-d21e-2454bfe9c31e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def f(arr,start,end):\n",
    "    if start>end:\n",
    "        return \n",
    "    else:\n",
    "        arr.append(start)             # start append进去构建sum的第二个加数，至此为止，两个加数都有了，可以开始斐波那契递归了。\n",
    "        second_last = arr[-2]         # 倒数第二个 \n",
    "        last = arr[-1]                # 倒数第一个\n",
    "        f(arr,second_last+last,end)   # 前两个数之和（second_last+last）为新的start\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    arr = [1]                         # 先填一个值进去，构建sum的第一个加数\n",
    "    f(arr,1,100)                      \n",
    "    print(arr)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "arr = [1]\n",
    "arr[-2]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "list index out of range",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a55174c866e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}