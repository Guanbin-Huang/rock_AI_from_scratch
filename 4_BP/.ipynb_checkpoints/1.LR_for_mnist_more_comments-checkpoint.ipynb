{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 今日知识点预报\n",
    "- mnist\n",
    "- softmax\n",
    "- 逻辑回归是怎么到bp的\n",
    "- bp框架\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST介绍\n",
    "ref: https://zhuanlan.zhihu.com/p/264960142 <br>\n",
    "首先下载mnist数据集<br>\n",
    "http://yann.lecun.com/exdb/mnist/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载和预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    return ez / ez.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def load_labels(file):\n",
    "    '''\n",
    "    解码标签文件\n",
    "    '''\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()  # kp: 任务整理 readlines  readline  and read 的区别\n",
    "    \n",
    "    magic_number, num_samples = struct.unpack(\">ii\", data[:8])  # refer to magic_number.jpg  # struct.unpack refer to https://docs.python.org/3/library/struct.html\n",
    "                                                                # >ii refer to https://docs.python.org/3/library/struct.html\n",
    "    if magic_number != 2049:\n",
    "        print(f\"magic number mismatch {magic_number} != 2049\")\n",
    "        return None\n",
    "\n",
    "    labels = np.array(list(data[8:])) # np.asarray  \n",
    "    return labels\n",
    "\"\"\" \n",
    "稍稍了解一下\n",
    "大端字节序和小端字节序\n",
    "big-endian and little-endian\n",
    " \"\"\"\n",
    "\n",
    "def load_images(file):\n",
    "    with open(file, \"rb\") as f: # note rb or r\n",
    "        data = f.read()\n",
    "    \n",
    "    magic_number, num_samples, image_height, image_width = struct.unpack(\">iiii\", data[:16])\n",
    "\n",
    "    if magic_number != 2051:\n",
    "        print(f\"magic number mismatch {magic_number} != 2051\")\n",
    "        return None\n",
    "    \n",
    "    image_data = np.array(list(data[16:]), dtype=np.uint8).reshape(num_samples, -1) # dtype = \"uint8\"\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "\n",
    "train_labels = load_labels(\"dataset/train-labels-idx1-ubyte\")\n",
    "train_images = load_images(\"dataset/train-images-idx3-ubyte\")\n",
    "train_numdata = train_labels.shape[0] # 60000\n",
    "train_pd = pd.DataFrame(train_labels, columns = [\"label\"])\n",
    "\n",
    "val_labels = load_labels(\"dataset/t10k-labels-idx1-ubyte\") # 10000\n",
    "val_images = load_images(\"dataset/t10k-images-idx3-ubyte\") # 10000, 784\n",
    "val_numdata = val_labels.shape[0]    # 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化数据 和 数据分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 19\n",
    "# plt.imshow(train_images[idx][:-1].reshape(28,28)) # 可视化第五张图片来看看\n",
    "# _ = plt.title(f\"label = {train_labels[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.ones((4,4), dtype = np.uint8)\n",
    "# np.ones((4,4), dtype = np.float32)\n",
    "# np.ones((4,4), dtype = np.float64) # 默认 64 \n",
    "# np.ones((4,4), dtype = \"float32\")\n",
    "# np.ones((4,4), dtype = \"float64\")\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    output = np.zeros((n, classes), dtype = np.int32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "    return output\n",
    "\n",
    "# one_hot(val_labels,10)\n",
    "\n",
    "def show_hist(labels, num_classes): # 常用的小工具函数的写法\n",
    "    label_map = {key: 0 for key in range(num_classes)} # 给每一个类都初始化： 数量为0\n",
    "    for label in labels:       # 循环labels，遇到label x  就去label x的keyvalue对里+1\n",
    "        label_map[label] += 1  # 这里相当于是一个一个label item去算\n",
    "    \n",
    "    # label_hist 是一个list, list 的值是 label_map key-value 对儿里的 value\n",
    "    labels_hist = [label_map[key] for key in range(num_classes)]  \n",
    "    pd.DataFrame(labels_hist, columns=[\"label\"]).plot(kind = \"bar\") # api 用法的形象记忆 refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "                                                                    # refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "show_hist(train_labels, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.453933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.889270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  60000.000000\n",
       "mean       4.453933\n",
       "std        2.889270\n",
       "min        0.000000\n",
       "25%        2.000000\n",
       "50%        4.000000\n",
       "75%        7.000000\n",
       "max        9.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1        6742\n",
       "7        6265\n",
       "3        6131\n",
       "2        5958\n",
       "9        5949\n",
       "0        5923\n",
       "6        5918\n",
       "8        5851\n",
       "4        5842\n",
       "5        5421\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pd.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_numdata, val_numdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建管理数据和数据加载的类\n",
    "回顾一下我们线性回归和逻辑回归，我们是怎么做数据管理的\n",
    "我们其实并没有做, 为什么？\n",
    "<br>因为数据量少\n",
    "<br>现在我们跟原来相比，我们训练集有60000张图片，任何东西一多了，我们就要管理，所以我们要搞一些类对数据进行管理\n",
    "<br>我们提出了三个类，分别是\n",
    "<br>class Dataset &nbsp;&nbsp; class DataLoader  &nbsp;&nbsp;  class DataLoaderIterator\n",
    "<br>为什么呢？先形象理解一下 \n",
    "\n",
    "- 查看 manage_dataset.jpg\n",
    "- 涉及到的知识点\n",
    "\n",
    "    - 有__iter__和__next__  iterator   iterable\n",
    "    - Iterable : 只要对象实现了__iter__ 就是可迭代对象     但是有时候依然无法迭代，因为实际iterable 仅仅是提供了一种抽象规范的接口  （简化代码等作用）\n",
    "    - Iterator:    迭代器肯定是iterable 的     但是iterable 不一定是iterator。只有实现了__next__ 和__iterable__的才是迭代器。(不严谨地说，也就是可以被for循环了)。换句话说： 要想被for loop 必须实现__next__  和__iterable__\n",
    "\t\n",
    "    \n",
    "- 严谨地说法是：\n",
    "\t要想for .. in ..某个类实例\n",
    "\t- 1.要么直接在这个类下直接实现__iter__ 和__next__\n",
    "\t- 2.要么只实现__iter__ ，但是__iter__ 返回的的对象实现了__next__\n",
    "\n",
    "- 注意__getitem__ 属于__iter__ 和__next__的高级封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    # 动态的，那么Dataset是个基类，所有动态的继承自Dataset\n",
    "    # 需要实现什么接口？\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "    # 针对mnist数据的解析、加载、预处理(e.g. /255 - 0.5), 加一个全是1的维度etc\n",
    "    def __init__(self, image_file, label_file):\n",
    "        self.num_classes = 10\n",
    "        self.images = load_images(image_file)\n",
    "        self.labels = load_labels(label_file)\n",
    "\n",
    "        # self.images = np.hstack((self.images / 255.0, np.ones((len(self.images), 1)))).astype(np.float32)\n",
    "        self.images = (self.images / 255.0).astype(np.float32)\n",
    "        self.labels_one_hot = one_hot(self.labels, self.num_classes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" \n",
    "        角色的职责\n",
    "        实现图像加载、归一化/标准化、onehot\n",
    "            为什么要返回one_hot，计算时，使用one_hot比较方便\n",
    "            为什么要返回label，因为做测试的时候，label比较方便\n",
    "            pytorch里面，CELoss使用的不是one_hot。所以以后不需要返回one_hot\n",
    "         \"\"\"\n",
    "        return self.images[index], self.labels[index], self.labels_one_hot[index]\n",
    "\n",
    "    # 获取数据集的长度，个数\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    职责\n",
    "    实例化的时候需要指定dataset，batch_size，shuffle\n",
    "    数据的封装，打包为一个batch\n",
    "    对数据进行打乱\n",
    "    可以通过迭代器来获取一批一批的数据\n",
    "     \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.count_data = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 实例化一个迭代器对象，将自身作为参数传入进去\n",
    "        return DataLoaderIterator(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" \n",
    "        用以告诉外界，多少次迭代，就算是完成一轮\n",
    "        这里有2种处理方法\n",
    "        1.向上取整\n",
    "        2.整除，向下取整，多余部分丢弃\n",
    "        这里考虑用策略2\n",
    "         \"\"\"\n",
    "        return len(self.dataset) // self.batch_size\n",
    "        \n",
    "\n",
    "class DataLoaderIterator:\n",
    "    \"\"\" \n",
    "    职责：\n",
    "        对打包好的batch一个一个的输出\n",
    "     \"\"\"\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        \n",
    "        # 这里有2中处理策略\n",
    "        # 1.向上取整\n",
    "        # 2.整除，向下取整，多余部分丢弃\n",
    "        # 这里考虑用方法2\n",
    "        self.num_batch_per_epoch = len(dataloader)\n",
    "        \n",
    "        # 定义指针记录当前batch的索引\n",
    "        self.batch_cursor = 0\n",
    "\n",
    "        # 实现一轮数据的打乱和封装获取\n",
    "        # 与其打乱数据，不如打乱索引\n",
    "        self.indexes = list(range(len(dataloader.dataset)))\n",
    "\n",
    "        # 如果需要随机打乱，条件控制由dataloader的shuffle决定\n",
    "        if dataloader.shuffle:\n",
    "            np.random.shuffle(self.indexes)  # inplace e.g. [0,1,2,3 ....59999] --> [2,1,48,23,...0]\n",
    "\n",
    "    \n",
    "    def __next__(self): # 指的是next batch\n",
    "        # 如果到了一轮的边界，即迭代结束，抛出异常 (一上来就做判断)\n",
    "        if self.batch_cursor >= self.num_batch_per_epoch:\n",
    "            # 如果到了边界，抛出StopIteration\n",
    "            raise StopIteration()\n",
    "        \"\"\" \n",
    "        职责：如何一个又一个的数据进行吐出, 每一行是一个数据\n",
    "            b1  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b2  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b3  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            ......\n",
    "            n 个 data\n",
    "        \n",
    "        images.shape = n x 784     labels.shape = n x 1        one_hot.shape = n x 10\n",
    "         \"\"\" \n",
    "\n",
    "        batch_data = []\n",
    "        for i in range(self.dataloader.batch_size): # 遍历一个batch里的图片\n",
    "            \"\"\" \n",
    "             拿到图像的索引，这个索引可能是打乱的\n",
    "              \"\"\"\n",
    "            index = self.indexes[self.batch_cursor * self.dataloader.batch_size + i] # 全局idx\n",
    "            \n",
    "            # 从dataset中拿到数据 e.g. 一个数据由图像和标签组成\n",
    "            data_item = self.dataloader.dataset[index]\n",
    "\n",
    "            if len(batch_data) == 0:\n",
    "                batch_data = [[] for _ in data_item] # 这里有3个\n",
    "            \n",
    "            # 把data_item中的每一项，分门别类的放到batch_data中\n",
    "            for index, item in enumerate(data_item):\n",
    "                batch_data[index].append(item)\n",
    "\n",
    "\n",
    "        # 遍历完了这个batch里的所有图片，要到下一个batch了\n",
    "        self.batch_cursor += 1\n",
    "\n",
    "        # 当整个batch的数据准备好过后，可以用np.vstack拼接在一起\n",
    "        for index in range(len(batch_data)):\n",
    "            batch_data[index] = np.vstack(batch_data[index])\n",
    "\n",
    "        return tuple(batch_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种init， 数据加载 和 数据预处理 权重初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化权重，和定义网络\n",
    "np.random.seed(3)\n",
    "num_train_images = train_images.shape[0]\n",
    "num_feature = train_images.shape[1]\n",
    "num_hidden = 256\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "lr = 0.1\n",
    "num_epochs = 30\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNIST_Dataset(\"dataset/train-images-idx3-ubyte\", \"dataset/train-labels-idx1-ubyte\")\n",
    "train_loader  = DataLoader(train_dataset, batch_size, True)\n",
    "test_dataset = MNIST_Dataset(\"dataset/t10k-images-idx3-ubyte\", \"dataset/t10k-labels-idx1-ubyte\")\n",
    "test_loader  = DataLoader(test_dataset, 512, True)\n",
    "\n",
    "\n",
    "# 初始化权重\n",
    "W = np.random.normal(0, 1, size = (num_feature, num_classes)) # (785, 10)\n",
    "W[:,-1] = 0.0\n",
    "b = -1\n",
    "# W\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. train_Loss: 0.847, test_Accuracy: 0.82370\n",
      "1. train_Loss: 0.750, test_Accuracy: 0.83960\n",
      "2. train_Loss: 0.722, test_Accuracy: 0.85580\n",
      "3. train_Loss: 0.085, test_Accuracy: 0.85730\n",
      "4. train_Loss: 0.603, test_Accuracy: 0.86430\n",
      "5. train_Loss: 0.405, test_Accuracy: 0.86700\n",
      "6. train_Loss: 0.179, test_Accuracy: 0.86920\n",
      "7. train_Loss: 0.576, test_Accuracy: 0.87400\n",
      "8. train_Loss: 0.642, test_Accuracy: 0.87370\n",
      "9. train_Loss: 0.205, test_Accuracy: 0.87270\n",
      "10. train_Loss: 0.995, test_Accuracy: 0.87590\n",
      "11. train_Loss: 0.323, test_Accuracy: 0.87590\n",
      "12. train_Loss: 0.084, test_Accuracy: 0.87970\n",
      "13. train_Loss: 0.718, test_Accuracy: 0.87920\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_688/2049214172.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0;31m# print(images.shape, labels.shape, one_hots.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_688/181954862.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m# 当整个batch的数据准备好过后，可以用np.vstack拼接在一起\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/datav/software/anaconda3/lib/python3.9/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mvstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# raise warning if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0m_arrays_for_stack_dispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m     \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/datav/software/anaconda3/lib/python3.9/site-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36matleast_2d\u001b[0;34m(*arys)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_atleast_2d_dispatcher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0matleast_2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for images, _, one_hot_labels in train_loader:\n",
    "        # print(images.shape, labels.shape, one_hots.shape)\n",
    "        # break\n",
    "        predict = images @ W + b\n",
    "        probability = softmax(predict)\n",
    "\n",
    "        # loss = -np.sum(one_hot_labels * np.log(probability) + (1 - one_hot_labels) * np.log(1 - probability)) / batch_size\n",
    "        loss = -np.sum(one_hot_labels * np.log(probability)) / batch_size\n",
    "\n",
    "        G = (probability - one_hot_labels) / batch_size\n",
    "\n",
    "        # matrix multiplication\n",
    "        del_W = images.T @ G\n",
    "        del_b = np.sum(G)\n",
    "        \n",
    "        W -= lr * del_W\n",
    "        b -= lr * del_b\n",
    "\n",
    "\n",
    "    # 每一个epoch 验证一次\n",
    "    correct = 0\n",
    "    for test_images, test_labels, test_one_hot_labels in test_loader:\n",
    "        predict = test_images @ W + b\n",
    "        predict_labels     = predict.argmax(axis=1).reshape(-1, 1)\n",
    "        \n",
    "        correct          += (predict_labels == test_labels).sum()\n",
    "    \n",
    "    acc = correct / len(test_dataset)\n",
    "    print(f\"{epoch}. train_Loss: {loss:.3f}, test_Accuracy: {acc:.5f}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7383003b210fdacca9bf7683d9d1d561f4a72c77adad40daede406a89507eb7d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
