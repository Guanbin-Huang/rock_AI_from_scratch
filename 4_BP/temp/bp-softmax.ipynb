{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\n",
    "\n",
    "import struct\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "\n",
    "\n",
    "def decode_labels(file):\n",
    "\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "\n",
    "    _, num_items = struct.unpack_from(\">II\", binary_data, 0)\n",
    "    labels = struct.unpack_from(\"B\" * num_items, binary_data, 8)\n",
    "    return np.array(labels).reshape(-1, 1).astype(np.int)\n",
    "\n",
    "\n",
    "def decode_images(file):\n",
    "\n",
    "    with open(file, \"rb\") as f:\n",
    "        binary_data = f.read()\n",
    "\n",
    "    _, num_images, rows, cols = struct.unpack_from(\">IIII\", binary_data, 0)\n",
    "    images = struct.unpack_from(\"B\" * (num_images * cols * rows), binary_data, 16)\n",
    "    return np.array(images).reshape(-1, rows * cols)\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    return x * (x > 0)\n",
    "\n",
    "def derelu(x):\n",
    "    return (x > 0).astype(np.float32)\n",
    "\n",
    "def sigmoid(x):\n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return np.clip(output, a_min=1e-4, a_max=1-1e-4)\n",
    "\n",
    "\n",
    "def desigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "def cross_entropy(target, predict):\n",
    "    return np.sum(target * np.log(predict) + (1 - target) * np.log(1 - predict))\n",
    "\n",
    "\n",
    "def softmax(predict):\n",
    "    exp_predict = np.exp(predict)\n",
    "    total = np.sum(exp_predict, axis=1, keepdims=True)\n",
    "    return exp_predict / total\n",
    "\n",
    "\n",
    "def softmaxLoss(target, predict):\n",
    "    return np.sum(target * np.log(predict))\n",
    "\n",
    "\n",
    "def one_hot(t, num_classes):\n",
    "    \n",
    "    rows = t.shape[0]\n",
    "    output = np.zeros((rows, num_classes))\n",
    "    \n",
    "    for row in range(rows):\n",
    "        label = t[row, 0]\n",
    "        output[row, label] = 1\n",
    "    return output\n",
    "\n",
    "def norm_image(image):\n",
    "    return (image / 255 - 0.5).astype(np.float32)\n",
    "\n",
    "def augment_image(image, images):\n",
    "    index = random.randint(0, images.shape[0] - 1)\n",
    "    alpha = random.random() * 0.2 + 0.8\n",
    "    beta = 1 - alpha\n",
    "    return image * alpha + images[index] * beta\n",
    "\n",
    "\n",
    "def label_smoothing(inputs, epsilon=0.3):\n",
    "    num_classes = inputs.shape[-1]\n",
    "    return (1 - epsilon) * inputs + epsilon / num_classes\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_images = decode_images(\"dataset/train-images-idx3-ubyte\")\n",
    "train_labels = decode_labels(\"dataset/train-labels-idx1-ubyte\")\n",
    "test_images = decode_images(\"dataset/t10k-images-idx3-ubyte\")\n",
    "test_labels = decode_labels(\"dataset/t10k-labels-idx1-ubyte\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "\n",
    "batch_size = 512\n",
    "num_hidden = 256\n",
    "num_output = 10\n",
    "num_train_images = train_images.shape[0]\n",
    "num_property = train_images.shape[1]\n",
    "learning_rate = 0.1\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "w_IH = np.random.normal(0, 1, size=(num_property, num_hidden))\n",
    "#w_IH = np.zeros((num_property, num_hidden)) \n",
    "b_IH = np.zeros((1, num_hidden))\n",
    "\n",
    "w_HO = np.random.normal(0, 1, size=(num_hidden, num_output))\n",
    "#w_HO = np.zeros((num_hidden, num_output))\n",
    "b_HO = np.zeros((1, num_output))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "batch_per_epoch = math.ceil(num_train_images / batch_size)\n",
    "train_epochs = 100"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "lr_schedule = {\n",
    "    0:  1e-1,\n",
    "    50: 1e-2,\n",
    "    80: 1e-3,\n",
    "    90: 1e-4\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "#### # 构建索引，0，1，2，3......num_train_images-1\n",
    "all_train_image_indexs = list(range(num_train_images))\n",
    "\n",
    "for epoch_index in range(train_epochs):\n",
    "    \n",
    "    if epoch_index in lr_schedule:\n",
    "        learning_rate = lr_schedule[epoch_index]\n",
    "    \n",
    "    # 打乱索引\n",
    "    random.shuffle(all_train_image_indexs)\n",
    "    \n",
    "    for batch_index in range(batch_per_epoch):\n",
    "        \n",
    "        index_begin = batch_index * batch_size\n",
    "        index_end = min(index_begin + batch_size, num_train_images)\n",
    "        \n",
    "        # 选择一个批次的索引\n",
    "        select_indexs = all_train_image_indexs[index_begin:index_end]\n",
    "        \n",
    "        # 预处理、归一化数据\n",
    "        train_batch_images = norm_image(train_images[select_indexs])\n",
    "        train_batch_labels = train_labels[select_indexs]\n",
    "        \n",
    "        if epoch_index < 90:\n",
    "            if random.random() < 0.1:\n",
    "                train_batch_labels[random.randint(0, len(train_batch_labels) - 1)] = random.randint(0, 9)\n",
    "        \n",
    "        #for sample_index in range(train_batch_images.shape[0]):\n",
    "        #    train_batch_images[sample_index] = augment_image(train_batch_images[sample_index], train_batch_images)\n",
    "        \n",
    "        # 转换label到one hot\n",
    "        train_batch_target = one_hot(train_batch_labels, num_classes = num_output)\n",
    "        \n",
    "        \n",
    "        #  bp  forward\n",
    "        #  ->  input to hidden\n",
    "        hidden = np.matmul(train_batch_images, w_IH) + b_IH\n",
    "        hidden_act = sigmoid(hidden)\n",
    "        \n",
    "        #  ->  hidden to output\n",
    "        output = np.matmul(hidden_act, w_HO) + b_HO\n",
    "        output_trans = softmax(output)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = -softmaxLoss(train_batch_target, output_trans) / batch_size\n",
    "        \n",
    "        # bp backward\n",
    "        loss_2_softmax = output_trans\n",
    "        loss_2_softmax[train_batch_target.astype(np.bool)] -= 1\n",
    "        delta_loss_2_output = (1 / batch_size) * loss_2_softmax\n",
    "        \n",
    "        # 隐层求导\n",
    "        delta_loss_2_b_HO = delta_loss_2_output\n",
    "        delta_loss_2_w_HO = np.matmul(delta_loss_2_output.T, hidden_act).T\n",
    "        \n",
    "        # 对hidden求导\n",
    "        delta_loss_2_hidden = np.matmul(delta_loss_2_output, w_HO.T) * desigmoid(hidden)\n",
    "        \n",
    "        # 对输入层求导\n",
    "        delta_loss_2_b_IH = delta_loss_2_hidden\n",
    "        delta_loss_2_w_IH = np.matmul(delta_loss_2_hidden.T, train_batch_images).T\n",
    "        \n",
    "        # 参数更新\n",
    "        w_IH = w_IH - learning_rate * delta_loss_2_w_IH\n",
    "        b_IH = b_IH - learning_rate * np.sum(delta_loss_2_b_IH, axis=0, keepdims=True)\n",
    "        \n",
    "        w_HO = w_HO - learning_rate * delta_loss_2_w_HO\n",
    "        b_HO = b_HO - learning_rate * np.sum(delta_loss_2_b_HO, axis=0, keepdims=True)\n",
    "        \n",
    "    print(\"Epoch: {}, Loss: {:.2f}, LR: {}\".format(epoch_index, loss, learning_rate))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Loss: 0.42, LR: 0.1\n",
      "Epoch: 1, Loss: 0.30, LR: 0.1\n",
      "Epoch: 2, Loss: 0.24, LR: 0.1\n",
      "Epoch: 3, Loss: 0.18, LR: 0.1\n",
      "Epoch: 4, Loss: 0.13, LR: 0.1\n",
      "Epoch: 5, Loss: 0.17, LR: 0.1\n",
      "Epoch: 6, Loss: 0.15, LR: 0.1\n",
      "Epoch: 7, Loss: 0.22, LR: 0.1\n",
      "Epoch: 8, Loss: 0.15, LR: 0.1\n",
      "Epoch: 9, Loss: 0.17, LR: 0.1\n",
      "Epoch: 10, Loss: 0.11, LR: 0.1\n",
      "Epoch: 11, Loss: 0.13, LR: 0.1\n",
      "Epoch: 12, Loss: 0.16, LR: 0.1\n",
      "Epoch: 13, Loss: 0.08, LR: 0.1\n",
      "Epoch: 14, Loss: 0.14, LR: 0.1\n",
      "Epoch: 15, Loss: 0.11, LR: 0.1\n",
      "Epoch: 16, Loss: 0.10, LR: 0.1\n",
      "Epoch: 17, Loss: 0.10, LR: 0.1\n",
      "Epoch: 18, Loss: 0.12, LR: 0.1\n",
      "Epoch: 19, Loss: 0.16, LR: 0.1\n",
      "Epoch: 20, Loss: 0.09, LR: 0.1\n",
      "Epoch: 21, Loss: 0.11, LR: 0.1\n",
      "Epoch: 22, Loss: 0.13, LR: 0.1\n",
      "Epoch: 23, Loss: 0.06, LR: 0.1\n",
      "Epoch: 24, Loss: 0.08, LR: 0.1\n",
      "Epoch: 25, Loss: 0.04, LR: 0.1\n",
      "Epoch: 26, Loss: 0.11, LR: 0.1\n",
      "Epoch: 27, Loss: 0.08, LR: 0.1\n",
      "Epoch: 28, Loss: 0.04, LR: 0.1\n",
      "Epoch: 29, Loss: 0.05, LR: 0.1\n",
      "Epoch: 30, Loss: 0.10, LR: 0.1\n",
      "Epoch: 31, Loss: 0.08, LR: 0.1\n",
      "Epoch: 32, Loss: 0.11, LR: 0.1\n",
      "Epoch: 33, Loss: 0.12, LR: 0.1\n",
      "Epoch: 34, Loss: 0.07, LR: 0.1\n",
      "Epoch: 35, Loss: 0.06, LR: 0.1\n",
      "Epoch: 36, Loss: 0.09, LR: 0.1\n",
      "Epoch: 37, Loss: 0.05, LR: 0.1\n",
      "Epoch: 38, Loss: 0.08, LR: 0.1\n",
      "Epoch: 39, Loss: 0.07, LR: 0.1\n",
      "Epoch: 40, Loss: 0.04, LR: 0.1\n",
      "Epoch: 41, Loss: 0.06, LR: 0.1\n",
      "Epoch: 42, Loss: 0.06, LR: 0.1\n",
      "Epoch: 43, Loss: 0.11, LR: 0.1\n",
      "Epoch: 44, Loss: 0.09, LR: 0.1\n",
      "Epoch: 45, Loss: 0.05, LR: 0.1\n",
      "Epoch: 46, Loss: 0.05, LR: 0.1\n",
      "Epoch: 47, Loss: 0.06, LR: 0.1\n",
      "Epoch: 48, Loss: 0.09, LR: 0.1\n",
      "Epoch: 49, Loss: 0.06, LR: 0.1\n",
      "Epoch: 50, Loss: 0.09, LR: 0.01\n",
      "Epoch: 51, Loss: 0.05, LR: 0.01\n",
      "Epoch: 52, Loss: 0.05, LR: 0.01\n",
      "Epoch: 53, Loss: 0.07, LR: 0.01\n",
      "Epoch: 54, Loss: 0.04, LR: 0.01\n",
      "Epoch: 55, Loss: 0.05, LR: 0.01\n",
      "Epoch: 56, Loss: 0.10, LR: 0.01\n",
      "Epoch: 57, Loss: 0.08, LR: 0.01\n",
      "Epoch: 58, Loss: 0.06, LR: 0.01\n",
      "Epoch: 59, Loss: 0.06, LR: 0.01\n",
      "Epoch: 60, Loss: 0.03, LR: 0.01\n",
      "Epoch: 61, Loss: 0.04, LR: 0.01\n",
      "Epoch: 62, Loss: 0.09, LR: 0.01\n",
      "Epoch: 63, Loss: 0.07, LR: 0.01\n",
      "Epoch: 64, Loss: 0.07, LR: 0.01\n",
      "Epoch: 65, Loss: 0.06, LR: 0.01\n",
      "Epoch: 66, Loss: 0.03, LR: 0.01\n",
      "Epoch: 67, Loss: 0.06, LR: 0.01\n",
      "Epoch: 68, Loss: 0.09, LR: 0.01\n",
      "Epoch: 69, Loss: 0.07, LR: 0.01\n",
      "Epoch: 70, Loss: 0.10, LR: 0.01\n",
      "Epoch: 71, Loss: 0.05, LR: 0.01\n",
      "Epoch: 72, Loss: 0.02, LR: 0.01\n",
      "Epoch: 73, Loss: 0.04, LR: 0.01\n",
      "Epoch: 74, Loss: 0.07, LR: 0.01\n",
      "Epoch: 75, Loss: 0.04, LR: 0.01\n",
      "Epoch: 76, Loss: 0.06, LR: 0.01\n",
      "Epoch: 77, Loss: 0.05, LR: 0.01\n",
      "Epoch: 78, Loss: 0.05, LR: 0.01\n",
      "Epoch: 79, Loss: 0.07, LR: 0.01\n",
      "Epoch: 80, Loss: 0.05, LR: 0.001\n",
      "Epoch: 81, Loss: 0.06, LR: 0.001\n",
      "Epoch: 82, Loss: 0.05, LR: 0.001\n",
      "Epoch: 83, Loss: 0.05, LR: 0.001\n",
      "Epoch: 84, Loss: 0.07, LR: 0.001\n",
      "Epoch: 85, Loss: 0.06, LR: 0.001\n",
      "Epoch: 86, Loss: 0.06, LR: 0.001\n",
      "Epoch: 87, Loss: 0.03, LR: 0.001\n",
      "Epoch: 88, Loss: 0.09, LR: 0.001\n",
      "Epoch: 89, Loss: 0.04, LR: 0.001\n",
      "Epoch: 90, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 91, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 92, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 93, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 94, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 95, Loss: 0.06, LR: 0.0001\n",
      "Epoch: 96, Loss: 0.05, LR: 0.0001\n",
      "Epoch: 97, Loss: 0.05, LR: 0.0001\n",
      "Epoch: 98, Loss: 0.07, LR: 0.0001\n",
      "Epoch: 99, Loss: 0.05, LR: 0.0001\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "plt.imshow(train_batch_images[2].reshape(28, 28))\n",
    "train_batch_labels[2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([9])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "image_index = 1000\n",
    "t_image = test_images[image_index]\n",
    "plt.imshow(t_image.reshape(28, 28), cmap=\"gray\"), test_labels[image_index]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x11c21ebe0>, array([9]))"
      ]
     },
     "metadata": {},
     "execution_count": 20
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "hidden = np.matmul(norm_image(test_images), w_IH) + b_IH\n",
    "hidden_act = sigmoid(hidden)\n",
    "output = np.matmul(hidden_act, w_HO) + b_HO\n",
    "output = softmax(output)\n",
    "\n",
    "all_predict_result = np.argmax(output, axis=1).reshape(-1, 1)\n",
    "#test_labels\n",
    "print(\"Image predict label: {}\".format(all_predict_result))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Image predict label: [[7]\n",
      " [2]\n",
      " [1]\n",
      " ...\n",
      " [4]\n",
      " [8]\n",
      " [6]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "accuracy = np.sum(test_labels == all_predict_result) / test_labels.shape[0] * 100\n",
    "print(\"train accuracy: {:.2f} %\".format(accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train accuracy: 89.72 %\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "(100,)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "metadata": {},
     "execution_count": 337
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "source": [
    "a = np.array([0.1, 0.8, -0.1, -0.5, 0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "relu(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 0.1,  0.8, -0. , -0. ,  0. ])"
      ]
     },
     "metadata": {},
     "execution_count": 341
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "source": [
    "derelu(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 344
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "source": [
    "np.clip(np.array([1, 2, 3, -1, -2, -3]), a_min=-2, a_max=2)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ 1,  2,  2, -1, -2, -2])"
      ]
     },
     "metadata": {},
     "execution_count": 367
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "a = [1, 2, 3, 2]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "softmax(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.07232949, 0.19661193, 0.53444665, 0.19661193])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "train_batch_labels[:, 0].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "output_trans.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "output_trans[train_batch_labels].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 1, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "a = np.array([[1, 2, 3],\n",
    "             [4, 5, 6]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "b = np.array([[0, 1, 0],\n",
    "             [0, 0, 1]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "source": [
    "a[b.astype(np.bool)]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([2, 6])"
      ]
     },
     "metadata": {},
     "execution_count": 53
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "output_trans[train_batch_target.astype(np.bool)].shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "source": [
    "delta_loss_2_b_HO.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "(np.log(output_trans * train_batch_target) * train_batch_target).shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(512, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "source": [
    "log_p = np.log(output_trans * train_batch_target)\n",
    "log_p[~train_batch_target.astype(np.bool)] = 0"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/datav/projects/Lesson/1.bp/venv/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in log\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "log_p"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        , -426.91773028],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        , -379.58645086],\n",
       "       ...,\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "           0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        , ...,    0.        ,\n",
       "        -735.6640592 ,    0.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "source": [
    "a = np.array([[1, 2, 3],\n",
    "              [4, 6, 7]])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "source": [
    "softmax(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.00171516, 0.0046623 , 0.01267344],\n",
       "       [0.03444998, 0.25455282, 0.6919463 ]])"
      ]
     },
     "metadata": {},
     "execution_count": 275
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "source": [
    "exp_predict = np.exp(a)\n",
    "total = np.sum(exp_predict, axis=1, keepdims=True)\n",
    "exp_predict / total"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0.09003057, 0.24472847, 0.66524096],\n",
       "       [0.03511903, 0.25949646, 0.70538451]])"
      ]
     },
     "metadata": {},
     "execution_count": 276
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "help(np.select)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on function select in module numpy:\n",
      "\n",
      "select(condlist, choicelist, default=0)\n",
      "    Return an array drawn from elements in choicelist, depending on conditions.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    condlist : list of bool ndarrays\n",
      "        The list of conditions which determine from which array in `choicelist`\n",
      "        the output elements are taken. When multiple conditions are satisfied,\n",
      "        the first one encountered in `condlist` is used.\n",
      "    choicelist : list of ndarrays\n",
      "        The list of arrays from which the output elements are taken. It has\n",
      "        to be of the same length as `condlist`.\n",
      "    default : scalar, optional\n",
      "        The element inserted in `output` when all conditions evaluate to False.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    output : ndarray\n",
      "        The output at position m is the m-th element of the array in\n",
      "        `choicelist` where the m-th element of the corresponding array in\n",
      "        `condlist` is True.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    where : Return elements from one of two arrays depending on condition.\n",
      "    take, choose, compress, diag, diagonal\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> x = np.arange(10)\n",
      "    >>> condlist = [x<3, x>5]\n",
      "    >>> choicelist = [x, x**2]\n",
      "    >>> np.select(condlist, choicelist)\n",
      "    array([ 0,  1,  2, ..., 49, 64, 81])\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "source": [
    "help(random.randint)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Help on method randint in module random:\n",
      "\n",
      "randint(a, b) method of random.Random instance\n",
      "    Return random integer in range [a, b], including both end points.\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "a = np.array([0, 0, 0, 1])\n",
    "label_smoothing(a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0.075, 0.075, 0.075, 0.775])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "7383003b210fdacca9bf7683d9d1d561f4a72c77adad40daede406a89507eb7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}