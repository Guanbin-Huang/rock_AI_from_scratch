{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "\"\"\" \n",
    "直接拿3.BP去改\n",
    "\n",
    "知识预告：\n",
    "    - 框架封装的理解\n",
    "    - 熟练使用debug来理解复杂程序\n",
    " \"\"\"\n",
    "\n",
    "# 数据加载和预处理\n",
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import math\n",
    "import pickle as pkl\n",
    "\n",
    "#-------------------------------------------------- 工具函数 ------------------------------------------------------\n",
    "#region\n",
    "def one_func_set_all_random_seed(seed=0):\n",
    "    # different random seeds\n",
    "    import torch\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "\n",
    "    import numpy as np\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "    # for dataloader\n",
    "    g = torch.Generator()\n",
    "    g.manual_seed(seed)\n",
    "\n",
    "    return g\n",
    "\n",
    "_ = one_func_set_all_random_seed()\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    return ez / ez.sum(axis=1, keepdims=True)\n",
    "\n",
    "\n",
    "def load_labels(file):\n",
    "    '''\n",
    "    解码标签文件\n",
    "    '''\n",
    "    with open(file, \"rb\") as f:\n",
    "        data = f.read()  # kp: 任务整理 readlines  readline  and read 的区别\n",
    "    \n",
    "    magic_number, num_samples = struct.unpack(\">ii\", data[:8])  # refer to magic_number.jpg  # struct.unpack refer to https://docs.python.org/3/library/struct.html\n",
    "                                                                # >ii refer to https://docs.python.org/3/library/struct.html\n",
    "    if magic_number != 2049:\n",
    "        print(f\"magic number mismatch {magic_number} != 2049\")\n",
    "        return None\n",
    "\n",
    "    labels = np.array(list(data[8:])) # np.asarray  \n",
    "    return labels\n",
    "\n",
    "def load_images(file):\n",
    "    with open(file, \"rb\") as f: # note rb or r\n",
    "        data = f.read()\n",
    "    \n",
    "    magic_number, num_samples, image_height, image_width = struct.unpack(\">iiii\", data[:16])\n",
    "\n",
    "    if magic_number != 2051:\n",
    "        print(f\"magic number mismatch {magic_number} != 2051\")\n",
    "        return None\n",
    "    \n",
    "    image_data = np.array(list(data[16:]), dtype=np.uint8).reshape(num_samples, -1) # dtype = \"uint8\"\n",
    "\n",
    "    return image_data\n",
    "\n",
    "\n",
    "def one_hot(labels, classes):\n",
    "    n = len(labels)\n",
    "    output = np.zeros((n, classes), dtype = np.int32)\n",
    "    for row, label in enumerate(labels):\n",
    "        output[row, label] = 1\n",
    "    return output\n",
    "\n",
    "def show_hist(labels, num_classes): # 常用的小工具函数的写法\n",
    "    label_map = {key: 0 for key in range(num_classes)} # 给每一个类都初始化： 数量为0\n",
    "    for label in labels:       # 循环labels，遇到label x  就去label x的keyvalue对里+1\n",
    "        label_map[label] += 1  # 这里相当于是一个一个label item去算\n",
    "    \n",
    "    # label_hist 是一个list, list 的值是 label_map key-value 对儿里的 value\n",
    "    labels_hist = [label_map[key] for key in range(num_classes)]  \n",
    "    pd.DataFrame(labels_hist, columns=[\"label\"]).plot(kind = \"bar\") # api 用法的形象记忆 refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html\n",
    "                                                                    # refer to https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html\n",
    "\n",
    "    evaluate(test_loader, W, b1, U, b2)\n",
    "    evaluate(test_loader, W, b1, U, b2)\n",
    "    evaluate(test_loader, W, b1, U, b2)\n",
    "\n",
    "    evaluate(test_loader, W, b1, U, b2)\n",
    "\n",
    "def evaluate(test_loader,model, epoch = None, loss = None):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for test_images, test_labels, _ in test_loader:\n",
    "        probability = softmax(model.inference(test_images))\n",
    "        predict_labels     = probability.argmax(axis=1).reshape(-1, 1)\n",
    "        correct       += (predict_labels == test_labels).sum()\n",
    "    \n",
    "    acc = correct / len(test_dataset)\n",
    "\n",
    "    if (epoch is not None) and (loss is not None):\n",
    "        print(f\"{epoch}. train_Loss: {loss:.3f}, test_Accuracy: {acc:.5f}\") \n",
    "    else:\n",
    "        print(f\"test_Accuracy: {acc:.5f}\") \n",
    "\n",
    "\n",
    "#endregion\n",
    "#-------------------------------------------------- 工具函数 ------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------- 数据集管理 ------------------------------------------------------\n",
    "#region\n",
    "# 创建管理数据和数据加载的类\n",
    "class Dataset:\n",
    "    # 动态的，那么Dataset是个基类，所有动态的继承自Dataset\n",
    "    # 需要实现什么接口？\n",
    "    def __getitem__(self, index):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "class MNIST_Dataset(Dataset):\n",
    "    # 针对mnist数据的解析、加载、预处理(e.g. /255), 加一个全是1的维度etc\n",
    "    def __init__(self, image_file, label_file, *args):\n",
    "        self.num_classes = 10\n",
    "        self.images = load_images(image_file)\n",
    "        self.labels = load_labels(label_file)\n",
    "\n",
    "        self.images = (self.images / 255.0 -0.5).astype(np.float64) # 64\n",
    "        self.images = (self.images - 0.130627) / 0.3081\n",
    "        self.labels_one_hot = one_hot(self.labels, self.num_classes)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" \n",
    "        角色的职责\n",
    "        实现图像加载、归一化/标准化、onehot\n",
    "            为什么要返回one_hot，计算时，使用one_hot比较方便\n",
    "            为什么要返回label，因为做测试的时候，label比较方便\n",
    "            pytorch里面，CELoss使用的不是one_hot。所以以后不需要返回one_hot\n",
    "         \"\"\"\n",
    "        return self.images[index], self.labels[index], self.labels_one_hot[index]\n",
    "\n",
    "    # 获取数据集的长度，个数\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    职责\n",
    "    实例化的时候需要指定dataset，batch_size，shuffle\n",
    "    数据的封装，打包为一个batch\n",
    "    对数据进行打乱\n",
    "    可以通过迭代器来获取一批一批的数据\n",
    "     \"\"\"\n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle = shuffle\n",
    "        self.count_data = len(dataset)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 实例化一个迭代器对象，将自身作为参数传入进去\n",
    "        return DataLoaderIterator(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\" \n",
    "        用以告诉外界，多少次迭代，就算是完成一轮\n",
    "        这里有2种处理方法\n",
    "        1.向上取整\n",
    "        2.整除，向下取整，多余部分丢弃\n",
    "        这里考虑用策略2\n",
    "         \"\"\"\n",
    "        return len(self.dataset) // self.batch_size\n",
    "        \n",
    "class DataLoaderIterator:\n",
    "    \"\"\" \n",
    "    职责：\n",
    "        对打包好的batch一个一个的输出\n",
    "     \"\"\"\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "        \n",
    "        # 这里有2中处理策略\n",
    "        # 1.向上取整\n",
    "        # 2.整除，向下取整，多余部分丢弃\n",
    "        # 这里考虑用方法2\n",
    "        self.num_batch_per_epoch = len(dataloader)\n",
    "        \n",
    "        # 定义指针记录当前batch的索引\n",
    "        self.batch_cursor = 0\n",
    "\n",
    "        # 实现一轮数据的打乱和封装获取\n",
    "        # 与其打乱数据，不如打乱索引\n",
    "        self.indexes = list(range(len(dataloader.dataset)))\n",
    "\n",
    "        # 如果需要随机打乱，条件控制由dataloader的shuffle决定\n",
    "        if dataloader.shuffle:\n",
    "            np.random.shuffle(self.indexes)  # inplace e.g. [0,1,2,3 ....59999] --> [2,1,48,23,...0]\n",
    "    \n",
    "    def __next__(self): # 指的是next batch\n",
    "        # 如果到了一轮的边界，即迭代结束，抛出异常 (一上来就做判断)\n",
    "        if self.batch_cursor >= self.num_batch_per_epoch:\n",
    "            # 如果到了边界，抛出StopIteration\n",
    "            raise StopIteration()\n",
    "        \"\"\" \n",
    "        职责：如何一个又一个的数据进行吐出, 每一行是一个数据\n",
    "            b1  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b2  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            b3  image.shape = 784,     label.shape = 1,     label_onehot.shape = 10,\n",
    "            ......\n",
    "            n 个 data\n",
    "        \n",
    "        images.shape = n x 784     labels.shape = n x 1        one_hot.shape = n x 10\n",
    "         \"\"\" \n",
    "\n",
    "        batch_data = []\n",
    "        for i in range(self.dataloader.batch_size): # 遍历一个batch里的图片\n",
    "            \"\"\" \n",
    "             拿到图像的索引，这个索引可能是打乱的\n",
    "              \"\"\"\n",
    "            index = self.indexes[self.batch_cursor * self.dataloader.batch_size + i] # 全局idx\n",
    "            # 从dataset中拿到数据 e.g. 一个数据由图像和标签组成\n",
    "            data_item = self.dataloader.dataset[index]\n",
    "\n",
    "            if len(batch_data) == 0:\n",
    "                batch_data = [[] for _ in data_item] # 这里有3个\n",
    "            \n",
    "            # 把data_item中的每一项，分门别类的放到batch_data中\n",
    "            for index, item in enumerate(data_item):\n",
    "                batch_data[index].append(item)\n",
    "\n",
    "\n",
    "        # 遍历完了这个batch里的所有图片，要到下一个batch了\n",
    "        self.batch_cursor += 1\n",
    "\n",
    "        # 当整个batch的数据准备好过后，可以用np.vstack拼接在一起\n",
    "        for index in range(len(batch_data)):\n",
    "            batch_data[index] = np.vstack(batch_data[index])\n",
    "\n",
    "        return tuple(batch_data)\n",
    "#endregion\n",
    "#-------------------------------------------------- 数据集管理 ------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------- 计算流程的管理 ------------------------------------------------------\n",
    "#region\n",
    "\n",
    "\"\"\" \n",
    "思考的时候可以参考下面的流程：\n",
    "    Parameter\n",
    "    Module\n",
    "    Linear\n",
    "    Sigmoid\n",
    "    SoftmaxCrossEntropyloss\n",
    "    Network ---> Sequential\n",
    "    Optimizer\n",
    "    SGD\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "\n",
    "class Module:\n",
    "    \"\"\" \n",
    "        1.可以称之为算子，那么他应该有forward、backward。为了简化代码，可以用__call__实现forward\n",
    "        2.需要实现以个params函数，拿出当前module下的所有【递归，如果有子类里面还有子类包含了参数，也要拿出来】参数实例\n",
    "        3.考虑有些算子，需要感知当前的环境属于训练还是推理，用 train_mode 储存是否为训练状态提供给特定算子用。通过\n",
    "        train方法和eval方法修改 train_mode 的值\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.train_mode = False # 为什么需要呢？一个模块的训练模式可能跟测试模式不一样。比如 模拟考搞点意外\n",
    "\n",
    "    def forward(self, *args):\n",
    "        # forward输入参数可以是多个\n",
    "        raise NotImplementedError() # NotImplementedError : https://blog.csdn.net/grey_csdn/article/details/77074707\n",
    "\n",
    "    def backward(self, grad):\n",
    "        # 假设算子输出只有一个，所以对应的梯度也应该只有一个\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "    def __call__(self, *args):  # __call__ ref: http://c.biancheng.net/view/2380.html  # 不定长参数\n",
    "        return self.forward(*args)\n",
    "\n",
    "    def train(self):\n",
    "        self.train_mode = True\n",
    "        for m in self.modules(): # 什么意思呢？即 你对任意一个module 开启 train mode 其实是对 它的 sub-module 开启train mode\n",
    "            m.train()\n",
    "\n",
    "    def eval(self):\n",
    "        self.train_mode = False\n",
    "        for m in self.modules():\n",
    "            m.eval()\n",
    "    \n",
    "    def modules(self): # 获取一个模块的所有子模块 这里没有递归\n",
    "        ms = []\n",
    "        for attr in self.__dict__: # __dict__  ref: 第一部分 重点理解obj.__dict__即可  https://www.cnblogs.com/starrysky77/p/9102344.html\n",
    "            m = self.__dict__[attr]\n",
    "            if isinstance(m, Module):\n",
    "                ms.append(m)\n",
    "\n",
    "        return ms\n",
    "\n",
    "    def params(self): # 获取一个模块所有的参数（如果有的话） 这里有递归\n",
    "        ps = []\n",
    "        for attr in self.__dict__:\n",
    "            p = self.__dict__[attr]     \n",
    "            if isinstance(p, Parameter): # 先看一下这个p是不是Parameter。kp: 这里用到了递归， 这里是递归的边界  不记得的建议去看一下 python 阶乘 递归\n",
    "                ps.append(p)            \n",
    "        \n",
    "        ms = self.modules()             # 如果不是Parameter的话就直接去找它的子模块（如果有的话）     \n",
    "        for m in ms:         \n",
    "            ps.extend(m.params())       # 对所有的子模块依次获取所有参数\n",
    "\n",
    "        return ps                 \n",
    "\n",
    "    # -----------------小工具方法（非重点）------------------\n",
    "    def info(self, n):\n",
    "        ms = self.modules()  # 拿到所有子模块\n",
    "        name = self.__class__.__name__ # 拿到当前模块的class 名称\n",
    "        output = f\"{name}\\n\" \n",
    "        for m in ms:         # 下面也是递归\n",
    "            output += ('  '*(n+1)) + f\"{m.info(n+1)}\\n\" # 顶头缩进，接着以同样的方式去打印它的子模块\n",
    "\n",
    "        return output[:-1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.info(0)\n",
    "        \n",
    "class Parameter:\n",
    "    \"\"\" \n",
    "    实例化的时候，传入参数值\n",
    "    封装data、和grad，储存参数值和梯度\n",
    "        grad.shape = forward(x).shape = batch_size x num_output\n",
    "        bias.shape = 1 x num_output\n",
    "     \"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.grad = np.zeros_like(data) # del_W 和 W 的形状要是一样大的\n",
    "\n",
    "    # 清空参数中存储的梯度\n",
    "    def zero_grad(self):   # 为什么要清空梯度？ ref: https://blog.csdn.net/weixin_42542536/article/details/104725921\n",
    "        self.grad[...] = 0 # inplace 操作\n",
    "\n",
    "class Linear(Module):\n",
    "    \"\"\"     \n",
    "    线性算子，线性层\n",
    "     职责:\n",
    "     包含了参数（parameter），包含了运算过程（forward、backward），对于输入的梯度计算，\n",
    "     和对于参数（parameter）的梯度计算\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input, num_output): # 回忆 W  比如: X @ W  = Y   [32x784]@[784x10] = [32x10]\n",
    "        super().__init__() # 你如果有继承请一定一定一定要写super\n",
    "        \n",
    "        # init method\n",
    "        # 试一下在这里加入or改成kaiming init\n",
    "        self.weight = Parameter(np.random.normal(0,1, size = (num_input, num_output)))\n",
    "        self.bias = Parameter(np.zeros((1, num_output)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 保存x给到backward时使用。 回忆 X @ W = Y    del_W = X^T @ G\n",
    "        self.x = x\n",
    "\n",
    "        return x @ self.weight.data + self.bias.data # 回忆一下，加入weight是[784,10] 那么bias形状是多大[10]\n",
    "    \n",
    "    def backward(self, grad):\n",
    "        \"\"\" \n",
    "        回忆矩阵乘法：\n",
    "            X @ W = Y\n",
    "            del_W = X^T @ G\n",
    "            del_X = G   @ W^T\n",
    "\n",
    "         \"\"\"\n",
    "        self.weight.grad += self.x.T @ grad  # 回忆一下所说的更新部分  # 为什么要写成+=????\n",
    "        self.bias.grad   += np.sum(grad, axis = 0, keepdims = True)\n",
    "        \n",
    "        return grad @ self.weight.data.T  # 和反传部分\n",
    "\n",
    "class Sigmoid(Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        self.out = 1 / (1 + np.exp(-z))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad):\n",
    "        return grad * self.out * (1 - self.out)\n",
    "    \n",
    "class SoftmaxCrossEntropyLoss(Module): # 一般的我们会把softmax 跟 loss合起来\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x, gt):\n",
    "        self.gt = gt\n",
    "        ex = np.exp(x)\n",
    "\n",
    "        # softmax部分\n",
    "        sum_ex = ex.sum(axis = 1, keepdims = True)\n",
    "        self.probability = ex / sum_ex\n",
    "        self.batch_size = x.shape[0]\n",
    "\n",
    "        # loss 部分\n",
    "        return -np.sum(self.gt * np.log(self.probability)) / self.batch_size\n",
    "\n",
    "    def backward(self, grad = 1):\n",
    "        return grad * (self.probability - self.gt) / self.batch_size\n",
    "\n",
    "class Sequential(Module):\n",
    "    def __init__(self, *items): # 初始化的时候放入一些模块\n",
    "        super().__init__()\n",
    "        self.items = items\n",
    "\n",
    "    def modules(self): # 只是返回最浅层即可\n",
    "        \"\"\" \n",
    "        覆盖基类的modules方法，直接返回items即可\n",
    "         \"\"\"\n",
    "        return self.items\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 按照顺序执行items即可\n",
    "        for m in self.items:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad):\n",
    "        # 按照反向顺序，执行items中模块的backward\n",
    "        for item in self.items[::-1]: # kp：逆序\n",
    "            grad = item.backward(grad)\n",
    "            \n",
    "        return grad\n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self, num_feature, num_hidden, num_classes): # 可以把Network理解成一个大矩阵。这里num_input就是num_feature 784\n",
    "        super().__init__()\n",
    "\n",
    "        self.layers = Sequential(\n",
    "            Linear(num_feature, num_hidden),\n",
    "            Sigmoid(),\n",
    "            Linear(num_hidden, num_classes)\n",
    "        )\n",
    "\n",
    "        self.loss = SoftmaxCrossEntropyLoss()\n",
    "\n",
    "\n",
    "    def inference(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "    def forward(self, x, gt):\n",
    "        # forward 和 inference 的不同，前者在训练的时候要算loss\n",
    "        return self.loss(self.inference(x), gt)\n",
    "\n",
    "    def backward(self, grad = 1):\n",
    "        grad = self.loss.backward(grad)\n",
    "        return self.layers.backward(grad)\n",
    "\n",
    "    def save(self, f):\n",
    "        param_list = []\n",
    "        for p in self.params():\n",
    "            data = p.data\n",
    "            grad = p.grad\n",
    "            param_list.append((data,grad))\n",
    "\n",
    "\n",
    "        pkl.dump(param_list,open(f\"{f}\",\"wb\"))\n",
    "        print(f\"the model has been saved.\")\n",
    "        \n",
    "            \n",
    "    def load(self, f):\n",
    "        param_list = pkl.load(open(f\"{f}\",\"rb\"))\n",
    "        param_module_list = self.params()\n",
    "\n",
    "        for idx ,p in enumerate(param_list): # \n",
    "            param_module_list[idx].data = p[0] # e.g. (784, 512) \n",
    "            param_module_list[idx].grad = p[1] # e.g. (784, 512)\n",
    "\n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "class Optimizer:\n",
    "    def __init__(self, params, lr = 0.1):\n",
    "        # 给我所有的params，我给你做更新和应用\n",
    "        self.params = params # ps = []\n",
    "        self.lr = lr\n",
    "\n",
    "    def step(sefl):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def zeros_grad(self):\n",
    "        # 清空所有参数中的梯度\n",
    "        # 如果需要累计梯度，可以自行控制\n",
    "        for param in self.params:\n",
    "            param.zero_grad() # 调用的是class Parameter 的 zero_grad()\n",
    "        \n",
    "    def set_lr(self, lr):\n",
    "        self.lr = lr\n",
    "\n",
    "class SGD(Optimizer):\n",
    "    def __init__(self, params, lr):\n",
    "        super().__init__(params, lr = lr)\n",
    "    \n",
    "    def step(self):\n",
    "        for param in self.params:\n",
    "            param.data -= self.lr * param.grad\n",
    "\n",
    "#endregion\n",
    "#-------------------------------------------------- 计算流程的管理 ------------------------------------------------------\n",
    "\n",
    "\n",
    "train_labels = load_labels(\"dataset/train-labels-idx1-ubyte\")\n",
    "train_images = load_images(\"dataset/train-images-idx3-ubyte\")\n",
    "train_numdata = train_labels.shape[0] # 60000\n",
    "\n",
    "val_labels = load_labels(\"dataset/t10k-labels-idx1-ubyte\") # 10000\n",
    "val_images = load_images(\"dataset/t10k-images-idx3-ubyte\") # 10000, 784\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- How to Transform Data to Better Fit The Normal Distribution\n",
    "- https://machinelearningmastery.com/how-to-transform-data-to-fit-the-normal-distribution/"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "from numpy import exp\n",
    "from matplotlib import pyplot\n",
    "# seed the random number generator\n",
    "# generate two sets of univariate observations\n",
    "# transform to be exponential\n",
    "\n",
    "data = np.exp(train_images / 255.0)\n",
    "pyplot.hist(data)\n",
    "pyplot.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "pyplot.hist(train_images / 255.0)\n",
    "pyplot.show()\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "pyplot.hist((train_images - 33.31002) / 78.567489)\n",
    "pyplot.show()"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU70lEQVR4nO3df4zc9Z3f8efrMCTo7jAmuAbZ7pnLWQcElAQscJTqlIYWDEUx0nFAVAUHcXEppM1JlVrnKhWXXKSkEpceKsfVCm5MlIYg7gduMOe6NtGlf5iwJA4EfCkbroi1AO9hApfSIyL37h/zMZ0ss7uzZndmFj8f0mi+3/f38/1+3zP2zmu+3/nubKoKSdLx7ReG3YAkafgMA0mSYSBJMgwkSRgGkiRgybAbOFann356rVmzZthtSNKi8dhjj/11VS3vtWzRhsGaNWsYGxsbdhuStGgkeXa6ZZ4mkiQZBpIkw0CShGEgScIwkCRhGEiS6DMMkpya5P4kf5nkYJIPJTktyZ4kT7f7ZW1sktyRZDzJ40ku6NrOpjb+6SSbuuoXJnmirXNHksz/Q5UkTaffI4M/AP68qs4G3g8cBLYAe6tqLbC3zQNcDqxtt83AXQBJTgNuBS4GLgJuPRogbcynutbb8PYeliRpLmYNgyRLgd8A7gaoqp9W1Y+BjcCONmwHcFWb3gjcUx37gVOTnAlcBuypqiNV9TKwB9jQlp1SVfur88cV7unaliRpAPo5MjgLmAT+S5LvJflykl8EVlTV823MC8CKNr0SeK5r/YlWm6k+0aP+Fkk2JxlLMjY5OdlH672dv+N8Dp59DrdfeyUTW77dc8zElm+zdevWabexd997WbPlwZ71Mx4+cMy9SdIw9BMGS4ALgLuq6oPA/+H/nxICoL2jX/A/mVZV26pqXVWtW76859drSJKOQT9hMAFMVNUjbf5+OuHwYjvFQ7s/3JYfAlZ3rb+q1Waqr+pRlyQNyKxhUFUvAM8l+fVWugR4CtgJHL0iaBPwQJveCVzfripaD7zSTiftBi5Nsqx9cHwpsLstezXJ+nYV0fVd25IkDUC/31r6L4CvJTkJeAa4gU6Q3JfkRuBZ4Jo2dhdwBTAOvNbGUlVHknwOeLSNu62qjrTpm4GvACcDD7WbJGlA+gqDqjoArOux6JIeYwu4ZZrtbAe296iPAef104skaf75G8iSJMNAkmQYSJIwDCRJGAaSJAwDSRKGwbya7nuOJGnUGQaz8EvnJB0PDINj8HPfZrp16dD6kKT5YhhIkgwD6PwNAkk6nhkGkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEn2GQZL/neSJJAeSjLXaaUn2JHm63S9r9SS5I8l4kseTXNC1nU1t/NNJNnXVL2zbH2/rZr4fqCRpenM5MviHVfWBqlrX5rcAe6tqLbC3zQNcDqxtt83AXdAJD+BW4GLgIuDWowHSxnyqa70Nx/yIJElz9nZOE20EdrTpHcBVXfV7qmM/cGqSM4HLgD1VdaSqXgb2ABvaslOqan9VFXBP17YkSQPQbxgU8N+TPJZkc6utqKrn2/QLwIo2vRJ4rmvdiVabqT7Ro/4WSTYnGUsyNjk52WfrkqTZLOlz3D+oqkNJ/h6wJ8lfdi+sqkpS89/ez6uqbcA2gHXr1i34/iTpeNHXkUFVHWr3h4E/pXPO/8V2iod2f7gNPwSs7lp9VavNVF/Voz40d960b5i7l6SBmzUMkvxikl8+Og1cCvwA2AkcvSJoE/BAm94JXN+uKloPvNJOJ+0GLk2yrH1wfCmwuy17Ncn6dhXR9V3bkiQNQD+niVYAf9qu9lwC/Neq+vMkjwL3JbkReBa4po3fBVwBjAOvATcAVNWRJJ8DHm3jbquqI236ZuArwMnAQ+0mSRqQWcOgqp4B3t+j/hJwSY96AbdMs63twPYe9THgvD76lSQtAH8DWZJkGEiSDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgG8+bOm/YNuwVJOmaGgSTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwmBcHzz5n2C1I0tvSdxgkOSHJ95J8s82fleSRJONJvpHkpFZ/V5sfb8vXdG3js63+wySXddU3tNp4ki3z+PgkSX2Yy5HBZ4CDXfNfBL5UVb8GvAzc2Oo3Ai+3+pfaOJKcC1wHvA/YAPxhC5gTgDuBy4FzgY+3sZKkAekrDJKsAv4J8OU2H+CjwP1tyA7gqja9sc3Tll/Sxm8E7q2q16vqr4Bx4KJ2G6+qZ6rqp8C9bawkaUD6PTL4j8C/Bv6uzb8H+HFVvdHmJ4CVbXol8BxAW/5KG/9mfco609XfIsnmJGNJxiYnJ/tsXZI0m1nDIMmVwOGqemwA/cyoqrZV1bqqWrd8+fJhtyNJ7xhL+hjzYeBjSa4A3g2cAvwBcGqSJe3d/yrgUBt/CFgNTCRZAiwFXuqqH9W9znR1SdIAzHpkUFWfrapVVbWGzgfA+6rqnwIPA1e3YZuAB9r0zjZPW76vqqrVr2tXG50FrAW+AzwKrG1XJ53U9rFzXh6dJKkv/RwZTOffAPcm+T3ge8DdrX438NUk48AROi/uVNWTSe4DngLeAG6pqp8BJPk0sBs4AdheVU++jb4kSXM0pzCoqm8B32rTz9C5EmjqmL8Ffmua9T8PfL5HfReway69SJLmj7+BLEkyDCRJhoEkCcOgL2u2PDjsFiRpQRkGkiTDQJJkGEiSMAwkSRgGkiQMgzm7/dorh92CJM07w0CSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShsGb/Gtmko5nhoEkyTCQJBkGkiT6CIMk707ynSTfT/Jkkn/f6mcleSTJeJJvJDmp1d/V5sfb8jVd2/psq/8wyWVd9Q2tNp5kywI8TknSDPo5Mngd+GhVvR/4ALAhyXrgi8CXqurXgJeBG9v4G4GXW/1LbRxJzgWuA94HbAD+MMkJSU4A7gQuB84FPt7GSpIGZNYwqI6ftNkT262AjwL3t/oO4Ko2vbHN05ZfkiStfm9VvV5VfwWMAxe123hVPVNVPwXubWMlSQPS12cG7R38AeAwsAf4EfDjqnqjDZkAVrbplcBzAG35K8B7uutT1pmu3quPzUnGkoxNTk7207okqQ99hUFV/ayqPgCsovNO/uyFbGqGPrZV1bqqWrd8+fJhtCBJ70hzupqoqn4MPAx8CDg1yZK2aBVwqE0fAlYDtOVLgZe661PWma4uSRqQfq4mWp7k1DZ9MvCPgYN0QuHqNmwT8ECb3tnmacv3VVW1+nXtaqOzgLXAd4BHgbXt6qST6HzIvHMeHtsxOXj2OcPatSQNzZLZh3AmsKNd9fMLwH1V9c0kTwH3Jvk94HvA3W383cBXk4wDR+i8uFNVTya5D3gKeAO4pap+BpDk08Bu4ARge1U9OW+PUJI0q1nDoKoeBz7Yo/4Mnc8Pptb/Fvitabb1eeDzPeq7gF199CtJWgD+BrIkyTCQJBkGkiQMA0kShkHfzt9x/rBbkKQFYxhIkgwDSZJhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYTAnd960b9gtSNKCMAwkSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEmijzBIsjrJw0meSvJkks+0+mlJ9iR5ut0va/UkuSPJeJLHk1zQta1NbfzTSTZ11S9M8kRb544kWYgHK0nqrZ8jgzeAf1VV5wLrgVuSnAtsAfZW1Vpgb5sHuBxY226bgbugEx7ArcDFwEXArUcDpI35VNd6G97+Q5Mk9WvWMKiq56vqu236b4CDwEpgI7CjDdsBXNWmNwL3VMd+4NQkZwKXAXuq6khVvQzsATa0ZadU1f6qKuCerm1JkgZgTp8ZJFkDfBB4BFhRVc+3RS8AK9r0SuC5rtUmWm2m+kSPeq/9b04ylmRscnJyLq1LkmbQdxgk+SXgj4HfqapXu5e1d/Q1z729RVVtq6p1VbVu+fLl87+DrUvnf5uSNEcHzz5n4PvsKwySnEgnCL5WVX/Syi+2Uzy0+8OtfghY3bX6qlabqb6qR12S3rGG8YI/k36uJgpwN3Cwqn6/a9FO4OgVQZuAB7rq17eritYDr7TTSbuBS5Msax8cXwrsbsteTbK+7ev6rm1JkgZgSR9jPgx8AngiyYFW+13gC8B9SW4EngWuact2AVcA48BrwA0AVXUkyeeAR9u426rqSJu+GfgKcDLwULtJkgZk1jCoqv8JTHfd/yU9xhdwyzTb2g5s71EfA86brRdJ0sLwN5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJGkm3X3vlQPdnGEiSDANJkmEgSQN1xsMHht1CT4aBJMkwkKRRcv6O84eyX8NAkmQYSJIMA0kShoEkCcNAkkQfYZBke5LDSX7QVTstyZ4kT7f7Za2eJHckGU/yeJILutbZ1MY/nWRTV/3CJE+0de5Ikvl+kJKkmfVzZPAVYMOU2hZgb1WtBfa2eYDLgbXtthm4CzrhAdwKXAxcBNx6NEDamE91rTd1X5KkBTZrGFTVXwBHppQ3Ajva9A7gqq76PdWxHzg1yZnAZcCeqjpSVS8De4ANbdkpVbW/qgq4p2tbkvTOtHXpsDt4i2P9zGBFVT3fpl8AVrTplcBzXeMmWm2m+kSPek9JNicZSzI2OTl5jK1LkqZ62x8gt3f0NQ+99LOvbVW1rqrWLV++fBC7lKTjwrGGwYvtFA/t/nCrHwJWd41b1Woz1Vf1qEuSBuhYw2AncPSKoE3AA13169tVReuBV9rppN3ApUmWtQ+OLwV2t2WvJlnfriK6vmtbkqQBWTLbgCRfBz4CnJ5kgs5VQV8A7ktyI/AscE0bvgu4AhgHXgNuAKiqI0k+Bzzaxt1WVUc/lL6ZzhVLJwMPtZskaYBmDYOq+vg0iy7pMbaAW6bZznZge4/6GHDebH1IkhaOv4EsSTIMJGlY7rxp37BbeJNhIEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpI0MtZseXBo+zYMJEmGgSTJMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJJ6uv3aK4fdwkAZBpKOP1uXAoP/s5N79713oPubC8NglLT/oNM5ePY5A2pEGr6JLd8edgvHFcNgRJzx8IFply3095Vs3bp1xv13Bs0cVDp2W7duHer+h/Gie/6O84HZT8Us5HMz05urUfpD9YNiGIyYoz8k/dbn1TQv+MMOozVbHlywMLr92itnfcGZNSiP0Z037Zv1xXDvvvcu2P4Pnn3OyL4YvxOs2fLgYH5u54lhMAJmOo+4UC8E/erubSF+eLvflfYKnUGdY53ueR7U/nvtZ9inSQa1/177Wch35rO9uel+AR/2UdsgGQaLzFveyW1d+o5/hzUsP/ci9Q47TTbbO9buF+NhvyE5ng0yjEYmDJJsSPLDJONJtgy7n+PF1Hdlcz6sXcAXyYX+QRjl88Kj3JvmZrG8WRuJMEhyAnAncDlwLvDxJOcOt6vFZSFePPp9MR7UedGF/qHqPn2w0NeYj1LowmAveZzLaRpY+COTYR8BDvt04FEjEQbARcB4VT1TVT8F7gU2DrmngTiW86VH1xnGX0XqfpHs/iE9ljDqtc6cT19sXTq0MDrj4QPz+m8wl21t3bp1wV7Ae4Xu1N7m8kahn/8bC/FYjn6A273/Y9nPsayzGE+tpaqG3QNJrgY2VNVvt/lPABdX1aenjNsMbG6zvw78sGvx6cBfD6DdhWL/w2X/w7WY+19Mvf9KVS3vtWDJoDt5O6pqG7Ct17IkY1W1bsAtzRv7Hy77H67F3P9i7r3bqJwmOgSs7ppf1WqSpAEYlTB4FFib5KwkJwHXATuH3JMkHTdG4jRRVb2R5NPAbuAEYHtVPTnHzfQ8fbSI2P9w2f9wLeb+F3PvbxqJD5AlScM1KqeJJElDZBhIkhZvGCQ5LcmeJE+3+2XTjPtZkgPtNvQPpWf72o0k70ryjbb8kSRrhtDmtPro/5NJJrue898eRp+9JNme5HCSH0yzPEnuaI/t8SQXDLrHmfTR/0eSvNL13P+7Qfc4nSSrkzyc5KkkTyb5TI8xI/v899n/yD7/famqRXkD/gOwpU1vAb44zbifDLvXrl5OAH4E/CpwEvB94NwpY24G/qhNXwd8Y9h9z7H/TwL/adi9TtP/bwAXAD+YZvkVwENAgPXAI8PueY79fwT45rD7nKa3M4EL2vQvA/+rx/+dkX3+++x/ZJ//fm6L9siAztdV7GjTO4CrhtdK3/r52o3ux3U/cEmSDLDHmSzqrw2pqr8AjswwZCNwT3XsB05NcuZguptdH/2PrKp6vqq+26b/BjgIrJwybGSf/z77X9QWcxisqKrn2/QLwIppxr07yViS/UmuGkxr01oJPNc1P8Fb/0O9Oaaq3gBeAd4zkO5m10//AL/ZDvPvT7K6x/JR1e/jG2UfSvL9JA8led+wm+mlnfr8IPDIlEWL4vmfoX9YBM//dEbi9wymk+R/AGf0WPRvu2eqqpJMd43sr1TVoSS/CuxL8kRV/Wi+e9Wb/hvw9ap6Pck/o3OU89Eh93S8+C6d/+8/SXIF8GfA2uG29POS/BLwx8DvVNWrw+5nrmbpf+Sf/5mM9JFBVf2jqjqvx+0B4MWjh5Dt/vA02zjU7p8BvkUn0Yeln6/deHNMkiXAUuClgXQ3u1n7r6qXqur1Nvtl4MIB9TYfFvXXolTVq1X1kza9CzgxyelDbutNSU6k80L6tar6kx5DRvr5n63/UX/+ZzPSYTCLncCmNr0JeGDqgCTLkryrTZ8OfBh4amAdvlU/X7vR/biuBvZV+3RqBMza/5RzvB+jc251sdgJXN+ualkPvNJ1KnLkJTnj6OdLSS6i8/M9Em8kWl93Awer6venGTayz38//Y/y89+PkT5NNIsvAPcluRF4FrgGIMk64KbqfB32OcB/TvJ3dP5hvlBVQwuDmuZrN5LcBoxV1U46/+G+mmSczoeF1w2r36n67P9fJvkY8Aad/j85tIanSPJ1Old8nJ5kArgVOBGgqv4I2EXnipZx4DXghuF02lsf/V8N/PMkbwD/F7huhN5IfBj4BPBEkgOt9rvA34dF8fz30/8oP/+z8usoJEmL+jSRJGmeGAaSJMNAkmQYSJIwDCRJGAaSJAwDSRLw/wBnHOQSrfytHQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "#-------------------------------------------------- 训练主干 ------------------------------------------------------\n",
    "#region\n",
    "#----------------------- 各种初始化 和 预处理 ------------------------\n",
    "# 重要超参\n",
    "num_train_images = train_images.shape[0]\n",
    "num_feature = train_images.shape[1]\n",
    "num_hidden = 512\n",
    "num_classes = 10\n",
    "batch_size = 32\n",
    "lr = 0.1\n",
    "num_epochs = 10\n",
    "\n",
    "# 加载数据\n",
    "train_dataset = MNIST_Dataset(\"dataset/train-images-idx3-ubyte\", \"dataset/train-labels-idx1-ubyte\")\n",
    "train_loader  = DataLoader(train_dataset, batch_size, True)\n",
    "test_dataset = MNIST_Dataset(\"dataset/t10k-images-idx3-ubyte\", \"dataset/t10k-labels-idx1-ubyte\")\n",
    "test_loader  = DataLoader(test_dataset, 500, False)\n",
    "\n",
    "# 定义网络结构\n",
    "model = Model(num_feature, num_hidden, num_classes)\n",
    "optim = SGD(model.params(), lr) # ??? network.params()为什么可以用\n",
    "\n",
    "#----------------------- TRAIN ------------------------\n",
    "print(f\"start training: \\nlr:{lr}  batchsize {batch_size}  num_hidden: {num_hidden}  epochs: {num_epochs}\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, labels, onehot_labels in train_loader:\n",
    "        \n",
    "        loss = model(images, onehot_labels)\n",
    "\n",
    "        optim.zeros_grad()\n",
    "        model.backward()\n",
    "        optim.step()\n",
    "\n",
    "    evaluate(test_loader, model, epoch, loss)\n",
    "\n",
    "# model.save(\"latest_model.pkl\")\n",
    "#endregion\n",
    "#-------------------------------------------------- 训练主干 ------------------------------------------------------\n",
    "\n",
    "# 读取预训练模型\n",
    "# model.load(\"latest_model.pkl\")\n",
    "# evaluate(test_loader, model)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "7383003b210fdacca9bf7683d9d1d561f4a72c77adad40daede406a89507eb7d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}